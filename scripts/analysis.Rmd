---
title: "analysis.rmd"
author: "chrysie"
date: "2024-06-13"
output: html_document
---

```{r }
library(tidyverse)

new_data <- read.csv("../data/our_data.csv", row.names = 1)

# trying to deal with the NAs with multiple imputation
#install.packages("mice")
library(mice)

# creating the imputation model
imp <- mice(new_data, method = rep("pmm", ncol(new_data)))

# making the imputated dataset
imputed_data <- complete(imp)

# summing the SDQ scores
  # getting each wave separated
cols_C1B <- new_data[, c("C1_B1", "C1_B2", "C1_B5", "C1_B10", "C1_B11", "C1_B12", "C1_B13", "C1_B14", "C1_B15", "C1_B16",
                               "C1_B17", "C1_B18", "C1_B19", "C1_B20", "C1_B21", "C1_B22", "C1_B23", "C1_B24", "C1_B25")]
                               
cols_C2B <- new_data[, c("C2_B1", "C2_B2", "C2_B5", "C2_B10", "C2_B11", "C2_B12", "C2_B13", "C2_B14", "C2_B15", "C2_B16",
                               "C2_B17", "C2_B18", "C2_B19", "C2_B20", "C2_B21", "C2_B22", "C2_B23", "C2_B24", "C2_B25")]

cols_C3B <- new_data[, c("C3_B1", "C3_B2", "C3_B5", "C3_B10", "C3_B11", "C3_B12", "C3_B13", "C3_B14", "C3_B15", "C3_B16",
                               "C3_B17", "C3_B18", "C3_B19", "C3_B20", "C3_B21", "C3_B22", "C3_B23", "C3_B24", "C3_B25")]

  # summing the scores for each wave
C1_Btotal <- rowSums(cols_C1B)
C2_Btotal <- rowSums(cols_C2B)
C3_Btotal <- rowSums(cols_C3B)


# summing the wentzel scores
# C1_AG1 to 4
cols_C1AG <- new_data[, c("C1_AG1", "C1_AG2", "C1_AG3", "C1_AG4")]
                  
cols_C2AG <- new_data[, c("C2_AG1", "C2_AG2", "C2_AG3", "C2_AG4")]

cols_C3AG <- new_data[, c("C3_AG1", "C3_AG2", "C3_AG3", "C3_AG4")]

  # summing the scores for each wave
C1_AGtotal <- rowSums(cols_C1AG)
C2_AGtotal <- rowSums(cols_C2AG)
C3_AGtotal <- rowSums(cols_C3AG)


# summing the SCQ
#C1_SConcern1 to 20

cols_C1SC <- new_data[, c("C1_SConcern1", "C1_SConcern2", "C1_SConcern3", "C1_SConcern4", "C1_SConcern5", "C1_SConcern6", "C1_SConcern7", "C1_SConcern8", "C1_SConcern9", "C1_SConcern10", "C1_SConcern11", "C1_SConcern12", "C1_SConcern13", "C1_SConcern14", "C1_SConcern15", "C1_SConcern16", "C1_SConcern17", "C1_SConcern18", "C1_SConcern19", "C1_SConcern20")]

cols_C2SC <- new_data[, c("C2_SConcern1", "C2_SConcern2", "C2_SConcern3", "C2_SConcern4", "C2_SConcern5", "C2_SConcern6", "C2_SConcern7", "C2_SConcern8", "C2_SConcern9", "C2_SConcern10", "C2_SConcern11", "C2_SConcern12", "C2_SConcern13", "C2_SConcern14", "C2_SConcern15", "C2_SConcern16", "C2_SConcern17", "C2_SConcern18", "C2_SConcern19", "C2_SConcern20")]

cols_C3SC <- new_data[, c("C3_SConcern1", "C3_SConcern2", "C3_SConcern3", "C3_SConcern4", "C3_SConcern5", "C3_SConcern6", "C3_SConcern7", "C3_SConcern8", "C3_SConcern9", "C3_SConcern10", "C3_SConcern11", "C3_SConcern12", "C3_SConcern13", "C3_SConcern14", "C3_SConcern15", "C3_SConcern16", "C3_SConcern17", "C3_SConcern18", "C3_SConcern19", "C3_SConcern20")]

  # summing the scores for each wave
C1_SCtotal <- rowSums(cols_C1SC)
C2_SCtotal <- rowSums(cols_C2SC)
C3_SCtotal <- rowSums(cols_C3SC)
 
  
#summing the liking teachers scores
#C1_LT1 to 10
cols_C1LT <- new_data[, c("C1_LT1", "C1_LT2", "C1_LT3", "C1_LT4", "C1_LT5", "C1_LT6", "C1_LT7", "C1_LT8", "C1_LT9", "C1_LT10")]
  
cols_C2LT <- new_data[, c("C2_LT1", "C2_LT2", "C2_LT3", "C2_LT4", "C2_LT5", "C2_LT7", "C2_LT6", "C2_LT8", "C2_LT9", "C2_LT10")]
  
cols_C3LT <- new_data[, c("C3_LT1", "C3_LT2", "C3_LT3", "C3_LT4", "C3_LT5", "C3_LT6", "C3_LT7", "C3_LT8", "C3_LT9", "C3_LT10")]

  # summing the scores for each wave
C1_LTtotal <- rowSums(cols_C1LT)
C2_LTtotal <- rowSums(cols_C2LT)
C3_LTtotal <- rowSums(cols_C3LT)


# summing the lonliness scores
#C1_L1 to 15
cols_C1L <- new_data[, c("C1_L1", "C1_L2", "C1_L3", "C1_L4", "C1_L5","C1_L6", "C1_L7","C1_L8","C1_L9", "C1_L10", "C1_L11", "C1_L12","C1_L13","C1_L14", "C1_L15")]

cols_C2L <- new_data[, c("C2_L1","C2_L2", "C2_L6", "C2_L7", "C2_L11", "C2_L14","C2_L15")]

cols_C3L <- new_data[, c("C3_L1", "C3_L2", "C3_L6", "C3_L7", "C3_L11", "C3_L14",   "C3_L15")]
  
  # summing the scores for each wave
C1_Ltotal <- rowSums(cols_C1L)
C2_Ltotal <- rowSums(cols_C2L)
C3_Ltotal <- rowSums(cols_C3L)


sum_data <- tibble(
  ID = new_data$ID,
  FSM = new_data$FSM,
  KS2Eng = new_data$KS2Eng,
  KS2Mat = new_data$KS2Mat,
  KS3Eng = new_data$KS3Eng,
  KS3Mat = new_data$KS3Mat,
  C1_Btotal = C1_Btotal,
  C2_Btotal = C2_Btotal,
  C3_Btotal = C3_Btotal,
  C1_AGtotal = C1_AGtotal,
  C2_AGtotal = C2_AGtotal,
  C3_AGtotal = C3_AGtotal,
  C1_SCtotal = C1_SCtotal,
  C2_SCtotal = C2_SCtotal,
  C3_SCtotal = C3_SCtotal,
  C1_LTtotal = C1_LTtotal,
  C2_LTtotal = C2_LTtotal,
  C3_LTtotal = C3_LTtotal,
  C1_Ltotal = C1_Ltotal,
  C2_Ltotal = C2_Ltotal,
  C3_Ltotal = C3_Ltotal
)


# removing ppts who have no data
rows_to_remove <- c()  # a vector to store indices of rows to remove

for (i in 1:nrow(sum_data)) {
  
  # checking for NA values in the current row
  row_na <- is.na(sum_data[i,])
  
  # counting the number of NA values in the row
  no_na <- sum(row_na)  
  
  # If there are exactly 20 NA values, exclude this row
  if (no_na == 20) {
    rows_to_remove <- c(rows_to_remove, i)
  }
}

# Remove rows with indices stored in rows_to_remove
sum_data <- sum_data[-rows_to_remove,]

# making a lil .csv so the project can be run from here onwards - it's like a game checkpoint
write.csv(sum_data, file = "../data/sum_data.csv", row.names = FALSE)

```

```{r}
library(tidyverse)

# adding NA values for the 2nd wave of data collection for grades because R can't handle things that aren't uniform
prep_data <- sum_data %>%
  rename(C1_Mat = KS2Mat, C3_Mat = KS3Mat, C1_Eng = KS2Eng, C3_Eng = KS3Eng) %>%
  mutate(C2_Eng = NA_real_, C2_Mat = NA_real_)

# converting the df to long format
long_data <- prep_data %>%
  pivot_longer(
    cols = matches("C[123]_"),
    names_to = c("timepoint", "measure"),
    names_pattern = "C(\\d+)_(.*)"
  ) %>%
  pivot_wider(
    names_from = measure,
    values_from = value
  ) %>%
  rename(Time = timepoint) %>%
  mutate(Time = factor(Time, levels = c("1", "2", "3"))) %>%
  arrange(ID, Time) %>%
  relocate(Time, .after = ID) %>%
  mutate(Time = as.numeric(Time)) %>%
  mutate_at(vars(ends_with("total")), ~replace_na(., 0)) %>%
  mutate_at(vars(FSM, Eng, Mat), ~replace_na(.,0))

#  long format checkpoint
write.csv(long_data, file = "../data/long_data.csv", row.names = FALSE)


```


```{r}
# imma visualise a little first coz that's gonna help me ac understand the onlsaught of numbers the lmer is gonna give me
library(ggplot2)

long_data %>% 
  group_by(Time) %>%
  mutate(tmean = mean(Btotal)) %>% 
  ggplot(mapping = aes(x = Time, y = tmean)) +
  geom_line() +
  labs(title = "SQD Score Over Time for Entire Sample",
       y = "SDQ score") +
    scale_x_discrete(limits = c(1, 2, 3))

# okay so overall, the average SDQ goes up from primary to secondary school

# split by FSM status
long_data %>% 
  group_by(Time, FSM) %>% 
  mutate(tmean = mean(Btotal)) %>% 
  ggplot(mapping = aes(x = Time, y = tmean, colour = factor(FSM))) +
  geom_line() +
  labs(title = "SDQ Score Over Time, FSM Status",
       y = "SDQ score") +
  scale_x_discrete(limits = c(1, 2, 3))

# overall those without FSM (1 - aka higher SES) have a higher SDQ throughout the primary-secondary school transition than those with FSM (2 - aka lower SES); but SDQ increases for both groups - NOTE: 0 indicated people who didn't indicate FSM status

# grades for english and maths
long_data %>%
  pivot_longer(cols = c(Eng, Mat), names_to = "Subject", values_to = "Grade") %>%
  group_by(Time, Subject) %>%
  summarize(tmean = mean(Grade, na.rm = TRUE), .groups = 'drop') %>%
  ggplot(aes(x = Time, y = tmean, color = Subject, group = Subject)) +
  geom_line() +
  labs(title = "Grades Over Time for Entire Sample",
       y = "Mean Grade",
       color = "Subject") +
  scale_x_discrete(limits = c(1, 2, 3))
# all i have to say for this is that it's embarrassing that the mean end of year grade for year 7 is a 4 for both english and math


```


```{r}
# linear mixed effects models
#"ID"  
#"Time"  
#"FSM" - fixed effect
#"Eng" - random effect
#"Mat" - random effect
#"Btotal" - random effect
#"AGtotal" - random effect
#"SCtotal" - random effect
#"LTtotal" - random effect
#"Ltotal"- random effect

#install.packages("lmerTest")
library(lmerTest)
model1 <- lmer(Btotal ~ 1 + Time + (Time|ID), data = long_data, REML = FALSE)
summary(model1)
{
#   Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite's
#   method [lmerModLmerTest]
# Formula: Btotal ~ 1 + Time + (Time | ID)
#    Data: long_data
# 
#      AIC      BIC   logLik deviance df.resid 
#  49672.3  49712.4 -24830.1  49660.3     5895 
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -1.8032 -0.8784  0.3137  0.8126  2.4229 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev. Corr 
#  ID       (Intercept)  64.154   8.010        
#           Time          8.051   2.837   -0.77
#  Residual             234.534  15.315        
# Number of obs: 5901, groups:  ID, 1967
# 
# Fixed effects:
#              Estimate Std. Error        df t value Pr(>|t|)    
# (Intercept)    6.8051     0.5575 1967.0829   12.21   <2e-16 ***
# Time           6.6627     0.2524 1967.1486   26.40   <2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#      (Intr)
# Time -0.910
}

# This LMM indicates that both Time (time) and the individual ID significantly influence Btotal (SDQ score). The negative correlation between random intercepts and slopes suggests that individuals with higher initial Btotal scores tend to have a smaller increase (or even a decrease) in Btotal over time.

# Overall, the model suggests that Btotal scores increase with time (Time), and there is significant variability both in the baseline scores (Intercept) and in how scores change over time (Time) across individuals (ID).

model2 <-  model2 <- lmer(Btotal ~ Time + FSM + 
               (1 + Time | ID) + 
               (1 + Time | Eng) + 
               (1 + Time | Mat) + 
               (1 + Time | AGtotal) + 
               (1 + Time | SCtotal) + 
               (1 + Time | LTtotal) + 
               (1 + Time | Ltotal), 
               data = long_data,
               REML = FALSE)
summary(model2)
{
# Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite's
#   method [lmerModLmerTest]
# Formula: Btotal ~ Time + FSM + (1 + Time | ID) + (1 + Time | Eng) + (1 +  
#     Time | Mat) + (1 + Time | AGtotal) + (1 + Time | SCtotal) +  
#     (1 + Time | LTtotal) + (1 + Time | Ltotal)
#    Data: long_data
# 
#      AIC      BIC   logLik deviance df.resid 
#  44895.3  45062.3 -22422.6  44845.3     5876 
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -3.4259 -0.1084  0.0627  0.4690  4.0145 
# 
# Random effects:
#  Groups   Name        Variance  Std.Dev. Corr 
#  ID       (Intercept)   0.42425  0.6513       
#           Time          3.29886  1.8163  -1.00
#  SCtotal  (Intercept)  15.37190  3.9207       
#           Time          2.04860  1.4313  -0.89
#  Ltotal   (Intercept)   4.19838  2.0490       
#           Time          0.23786  0.4877  1.00 
#  LTtotal  (Intercept)   0.17437  0.4176       
#           Time          0.14576  0.3818  1.00 
#  AGtotal  (Intercept)  50.82182  7.1289       
#           Time          2.31825  1.5226  -1.00
#  Mat      (Intercept)   0.00000  0.0000       
#           Time          0.21454  0.4632   NaN 
#  Eng      (Intercept)   0.00000  0.0000       
#           Time          0.06565  0.2562   NaN 
#  Residual             102.09846 10.1044       
# Number of obs: 5901, groups:  
# ID, 1967; SCtotal, 149; Ltotal, 51; LTtotal, 32; AGtotal, 18; Mat, 9; Eng, 8
# 
# Fixed effects:
#              Estimate Std. Error        df t value Pr(>|t|)    
# (Intercept)   34.4475     2.0882   26.4729  16.497 1.89e-15 ***
# Time          -0.7155     0.5997   24.5945  -1.193   0.2442    
# FSM           -0.6443     0.2802 1526.1509  -2.299   0.0216 *  
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#      (Intr) Time  
# Time -0.792       
# FSM  -0.143  0.012
# optimizer (nloptwrap) convergence code: 0 (OK)
# boundary (singular) fit: see help('isSingular')
}

isSingular(model2) # TRUE

# icba to deal with this now - i have to get rid of some multicollinearity that's begin created by the excessive inclusion fo intercepts and slopes but imma try to wrap my head around this later

```

```{r}
# take 2 on lme models
library(lme4)

# Model with random intercept only
ri_model <- lmer(Btotal ~ Time + FSM + (1 | ID), data = long_data)

# Model with random intercept and random slope for Time
rs_model <- lmer(Btotal ~ Time + FSM + (1 + Time | ID), data = long_data)

intelligence_model <- lmer(Btotal ~ Time + FSM + (1 + Time + AGtotal + SCtotal + LTtotal + Ltotal | ID ), data = long_data)

AIC(ri_model, rs_model)

```


```{r}
# SEM models

#install.packages("lavaan")
library(lavaan)

## taken from CA stats coursework
# mod.spec2 <- 'grp =~ 1*bart + grips + soep + forb
# bart =~ adj_bart_score_early + adj_bart_score_middle + adj_bart_score_late 
# grips =~ grips_commonly + grips_attracted + grips_chances + grips_fun + grips_enjoy + grips_part + grips_hurt + grips_friends
# soep =~ soep_leisure + soep_health + soep_driving + soep_occupation + soep_faith + soep_finance + soep_general
# forb =~ forb_gamble + forb_sport + forb_cigarettes + forb_invest + forb_speed + forb_drink'
# 
# model2 <- lavaan::cfa(mod.spec2, data = wide.z)
# 
# (mod2.sum <- summary(model2, fit.measures = TRUE))

sem_model1 <- '
  C1_Btotal ~ KS2Eng + KS2Mat + C1_AGtotal + C1_SCtotal + C1_LTtotal + C1_Ltotal + FSM
  C2_Btotal ~ C2_AGtotal + C2_SCtotal + C2_LTtotal + C2_Ltotal + FSM
  C3_Btotal ~ KS3Eng + KS3Mat + C3_AGtotal + C3_SCtotal + C3_LTtotal + C3_Ltotal + FSM '

# fitting the model made
sem_fit1 <- sem(sem_model1, data = sum_data, missing="fiml", fixed.x=FALSE)

# having a lil look-see at all the ugly stats that are supposed ot mean something to me
summary(sem_fit1, fit.measures=TRUE)

```

```{r}
# the graveyard

T1 <- rep(1,nrow(sum_data))
T2 <- rep(2,nrow(sum_data))
T3 <- rep(3,nrow(sum_data))

testsum_data <- cbind(sum_data, T1, T2, T3)

ggplot(data = testsum_data, aes(x = T1, y = C1_Btotal)) + geom_point()

ggplot(data = testsum_data, aes(x = T2, y = C2_Btotal)) + geom_point()

# Reshape the data
testsum_long <- testsum_data %>%
  pivot_longer(cols = starts_with("T"), names_to = "Time", values_to = "TimeValue") %>%
  pivot_longer(cols = starts_with("C"), names_to = "BtotalType", values_to = "BtotalValue")

# Filter to match the correct pairs
testsum_long <- testsum_long %>%
  filter((Time == "T1" & BtotalType == "C1_Btotal") | (Time == "T2" & BtotalType == "C2_Btotal") | (Time == "T3" & BtotalType == "C3_Btotal"))

ggplot(data = testsum_long, aes(x = TimeValue, y = BtotalValue, color = Time, group = ID)) +
  geom_line() +
  labs(x = "Time", y = "Btotal Scores", color = "Time") +
  scale_color_manual(values = c("T1" = "blue", "T2" = "red")) +  # Customize line colors
  theme_minimal()
```
