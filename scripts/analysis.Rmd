---
title: "analysis.rmd"
author: "chrysie"
date: "2024-06-13"
output: html_document
---

```{r set up}
library(tidyverse)

our_data <- read.csv("../data/our_data.csv", row.names = 1)

# trying to deal with the NAs with multiple imputation
#install.packages("mice")
library(mice)

# creating the imputation model
imp <- mice(our_data, method = rep("pmm", ncol(new_data)))

# making the imputated dataset
new_data <- complete(imp)

# saving the new data frame because the imputation takes a hot minute so there's no need to re run it every time we open this script
write.csv(new_data, file = "../data/new_data.csv", row.names = FALSE)

```

```{r creating the summed data frame}
# calling the imputed data into the envrionment
new_data <- read.csv("../data/new_data.csv")

# summing the SDQ scores
  # getting each wave separated
cols_C1B <- new_data[, c("C1_B1", "C1_B2", "C1_B5", "C1_B10", "C1_B11", "C1_B12", "C1_B13", "C1_B14", "C1_B15", "C1_B16",
                               "C1_B17", "C1_B18", "C1_B19", "C1_B20", "C1_B21", "C1_B22", "C1_B23", "C1_B24", "C1_B25")]
                               
cols_C2B <- new_data[, c("C2_B1", "C2_B2", "C2_B5", "C2_B10", "C2_B11", "C2_B12", "C2_B13", "C2_B14", "C2_B15", "C2_B16",
                               "C2_B17", "C2_B18", "C2_B19", "C2_B20", "C2_B21", "C2_B22", "C2_B23", "C2_B24", "C2_B25")]

cols_C3B <- new_data[, c("C3_B1", "C3_B2", "C3_B5", "C3_B10", "C3_B11", "C3_B12", "C3_B13", "C3_B14", "C3_B15", "C3_B16",
                               "C3_B17", "C3_B18", "C3_B19", "C3_B20", "C3_B21", "C3_B22", "C3_B23", "C3_B24", "C3_B25")]

  # summing the scores for each wave
C1_Btotal <- rowSums(cols_C1B)
C2_Btotal <- rowSums(cols_C2B)
C3_Btotal <- rowSums(cols_C3B)


# summing the wentzel scores
# C1_AG1 to 4
cols_C1AG <- new_data[, c("C1_AG1", "C1_AG2", "C1_AG3", "C1_AG4")]
                  
cols_C2AG <- new_data[, c("C2_AG1", "C2_AG2", "C2_AG3", "C2_AG4")]

cols_C3AG <- new_data[, c("C3_AG1", "C3_AG2", "C3_AG3", "C3_AG4")]

  # summing the scores for each wave
C1_AGtotal <- rowSums(cols_C1AG)
C2_AGtotal <- rowSums(cols_C2AG)
C3_AGtotal <- rowSums(cols_C3AG)


# summing the SCQ
#C1_SConcern1 to 20

cols_C1SC <- new_data[, c("C1_SConcern1", "C1_SConcern2", "C1_SConcern3", "C1_SConcern4", "C1_SConcern5", "C1_SConcern6", "C1_SConcern7", "C1_SConcern8", "C1_SConcern9", "C1_SConcern10", "C1_SConcern11", "C1_SConcern12", "C1_SConcern13", "C1_SConcern14", "C1_SConcern15", "C1_SConcern16", "C1_SConcern17", "C1_SConcern18", "C1_SConcern19", "C1_SConcern20")]

cols_C2SC <- new_data[, c("C2_SConcern1", "C2_SConcern2", "C2_SConcern3", "C2_SConcern4", "C2_SConcern5", "C2_SConcern6", "C2_SConcern7", "C2_SConcern8", "C2_SConcern9", "C2_SConcern10", "C2_SConcern11", "C2_SConcern12", "C2_SConcern13", "C2_SConcern14", "C2_SConcern15", "C2_SConcern16", "C2_SConcern17", "C2_SConcern18", "C2_SConcern19", "C2_SConcern20")]

cols_C3SC <- new_data[, c("C3_SConcern1", "C3_SConcern2", "C3_SConcern3", "C3_SConcern4", "C3_SConcern5", "C3_SConcern6", "C3_SConcern7", "C3_SConcern8", "C3_SConcern9", "C3_SConcern10", "C3_SConcern11", "C3_SConcern12", "C3_SConcern13", "C3_SConcern14", "C3_SConcern15", "C3_SConcern16", "C3_SConcern17", "C3_SConcern18", "C3_SConcern19", "C3_SConcern20")]

  # summing the scores for each wave
C1_SCtotal <- rowSums(cols_C1SC)
C2_SCtotal <- rowSums(cols_C2SC)
C3_SCtotal <- rowSums(cols_C3SC)
 
  
#summing the liking teachers scores
#C1_LT1 to 10
cols_C1LT <- new_data[, c("C1_LT1", "C1_LT2", "C1_LT3", "C1_LT4", "C1_LT5", "C1_LT6", "C1_LT7", "C1_LT8", "C1_LT9", "C1_LT10")]
  
cols_C2LT <- new_data[, c("C2_LT1", "C2_LT2", "C2_LT3", "C2_LT4", "C2_LT5", "C2_LT7", "C2_LT6", "C2_LT8", "C2_LT9", "C2_LT10")]
  
cols_C3LT <- new_data[, c("C3_LT1", "C3_LT2", "C3_LT3", "C3_LT4", "C3_LT5", "C3_LT6", "C3_LT7", "C3_LT8", "C3_LT9", "C3_LT10")]

  # summing the scores for each wave
C1_LTtotal <- rowSums(cols_C1LT)
C2_LTtotal <- rowSums(cols_C2LT)
C3_LTtotal <- rowSums(cols_C3LT)


# summing the lonliness scores
#C1_L1 to 15
cols_C1L <- new_data[, c("C1_L1", "C1_L2", "C1_L3", "C1_L4", "C1_L5","C1_L6", "C1_L7","C1_L8","C1_L9", "C1_L10", "C1_L11", "C1_L12","C1_L13","C1_L14", "C1_L15")]

cols_C2L <- new_data[, c("C2_L1","C2_L2", "C2_L6", "C2_L7", "C2_L11", "C2_L14","C2_L15")]

cols_C3L <- new_data[, c("C3_L1", "C3_L2", "C3_L6", "C3_L7", "C3_L11", "C3_L14",   "C3_L15")]
  
  # summing the scores for each wave
C1_Ltotal <- rowSums(cols_C1L)
C2_Ltotal <- rowSums(cols_C2L)
C3_Ltotal <- rowSums(cols_C3L)


sum_data <- tibble(
  ID = new_data$ID,
  FSM = new_data$FSM,
  C1_Eng = new_data$KS2Eng,
  C1_Mat = new_data$KS2Mat,
  C2_Eng = new_data$KS2Eng,
  C2_Mat = new_data$KS2Mat,
  C3_Eng = new_data$KS3Eng,
  C3_Mat = new_data$KS3Mat,
  C1_Btotal = C1_Btotal,
  C2_Btotal = C2_Btotal,
  C3_Btotal = C3_Btotal,
  C1_AGtotal = C1_AGtotal,
  C2_AGtotal = C2_AGtotal,
  C3_AGtotal = C3_AGtotal,
  C1_SCtotal = C1_SCtotal,
  C2_SCtotal = C2_SCtotal,
  C3_SCtotal = C3_SCtotal,
  C1_LTtotal = C1_LTtotal,
  C2_LTtotal = C2_LTtotal,
  C3_LTtotal = C3_LTtotal,
  C1_Ltotal = C1_Ltotal,
  C2_Ltotal = C2_Ltotal,
  C3_Ltotal = C3_Ltotal
)


# making a lil .csv so the project can be run from here on wards - it's like a game checkpoint
write.csv(sum_data, file = "../data/sum_data.csv", row.names = FALSE)

```

```{r getting the data into long format}
library(tidyverse)

# converting the df to long format
long_data <- sum_data %>%
  pivot_longer(
    cols = matches("C[123]_"),
    names_to = c("timepoint", "measure"),
    names_pattern = "C(\\d+)_(.*)"
  ) %>%
  pivot_wider(
    names_from = measure,
    values_from = value
  ) %>%
  rename(Time = timepoint) %>%
  mutate(Time = factor(Time, levels = c("1", "2", "3"))) %>%
  arrange(ID, Time) %>%
  relocate(Time, .after = ID) %>%
  mutate(Time = as.numeric(Time)) %>%
  mutate_at(vars(ends_with("total")), ~replace_na(., 0)) %>%
  mutate_at(vars(FSM, Eng, Mat), ~replace_na(.,0))

#  long format checkpoint
write.csv(long_data, file = "../data/long_data.csv", row.names = FALSE)

```

```{r visualising the data}
# imma visualise a little first coz that's gonna help me ac understand the onlsaught of numbers the lmer is gonna give me
library(ggplot2)

long_data %>% 
  group_by(Time) %>%
  mutate(tmean = mean(Btotal)) %>% 
  ggplot(mapping = aes(x = Time, y = tmean)) +
  geom_line() +
  labs(title = "SQD Score Over Time for Entire Sample",
       y = "SDQ score") +
  scale_x_continuous(breaks = c(1,2,3))

# okay so overall, the average SDQ goes down from primary to secondary school

# split by FSM status
long_data %>% 
  group_by(Time, FSM) %>% 
  mutate(tmean = mean(Btotal)) %>% 
  ggplot(mapping = aes(x = Time, y = tmean, colour = factor(FSM))) +
  geom_line() +
  labs(title = "SDQ Score Over Time, FSM Status",
       y = "SDQ score") +
  scale_x_continuous(breaks = c(1,2,3))

# overall those without FSM (1 - aka higher SES) have a higher SDQ throughout the primary-secondary school transition than those with FSM (2 - aka lower SES); but SDQ increases for both groups - NOTE: 0 indicated people who didn't indicate FSM status

# grades for english and maths
long_data %>%
  pivot_longer(cols = c(Eng, Mat), names_to = "Subject", values_to = "Grade") %>%
  group_by(Time, Subject) %>%
  summarize(tmean = mean(Grade, na.rm = TRUE), .groups = 'drop') %>%
  ggplot(aes(x = Time, y = tmean, color = Subject, group = Subject)) +
  geom_line() +
  labs(title = "Grades Over Time for Entire Sample",
       y = "Mean Grade",
       color = "Subject") +
  scale_x_continuous(breaks = c(1,2,3))
# all i have to say for this is that it's embarrassing that the mean end of year grade for year 7 is a 4 for both english and math

# note to self: this should work now with he as.factor() argument
ggplot(data = long_data, aes(x = Time, y = Btotal, colour = as.factor(ID))) +
  geom_line() +
  theme_minimal () +
  theme(legend.position = "none") +
  scale_x_continuous(breaks = c(1,2,3))
```

```{r linear-mixed effects models}
# take 2 on lme models
# note: random intercepts go after the | and random slopes go after (1 +
#install.packages("lme4")
library(lme4)

# Model with random intercept only
base_model <- lmer(Btotal ~ Time + (1 | ID), data = long_data)
summary(base_model)
{
#   Linear mixed model fit by REML ['lmerMod']
# Formula: Btotal ~ Time + (1 | ID)
#    Data: long_data
# 
# REML criterion at convergence: 37659.5
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -5.3393 -0.5772 -0.0595  0.5029  4.9919 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  ID       (Intercept)  5.478   2.341   
#  Residual             10.086   3.176   
# Number of obs: 6882, groups:  ID, 2294
# 
# Fixed effects:
#             Estimate Std. Error t value
# (Intercept) 35.16274    0.11246 312.670
# Time        -0.18112    0.04689  -3.863
# 
# Correlation of Fixed Effects:
#      (Intr)
# Time -0.834
}
# The model indicates that Btotal decreases slightly over time, and this effect is statistically significant.
# There is significant variability in the intercepts across different individuals (ID), suggesting that individual differences account for a substantial portion of the variance in Btotal.
# The high t values for both the intercept and the Time coefficient suggest that these fixed effects are very significant predictors of Btotal.


# model considering the effect of FSMs on SDQ over time
fixed_model<-lmer(Btotal ~ Time + FSM + (1 | ID), data = long_data)
summary(fixed_model)
{
#   Linear mixed model fit by REML ['lmerMod']
# Formula: Btotal ~ Time + FSM + (1 | ID)
#    Data: long_data
# 
# REML criterion at convergence: 37639.6
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -5.3205 -0.5726 -0.0644  0.4937  5.0201 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  ID       (Intercept)  5.399   2.324   
#  Residual             10.086   3.176   
# Number of obs: 6882, groups:  ID, 2294
# 
# Fixed effects:
#             Estimate Std. Error t value
# (Intercept) 34.28607    0.21876 156.727
# Time        -0.18112    0.04689  -3.863
# FSM          0.73748    0.15793   4.670
# 
# Correlation of Fixed Effects:
#      (Intr) Time  
# Time -0.429       
# FSM  -0.858  0.000
}
# The intercept (34.28607) represents the estimated value of Btotal when Time and FSM are both zero.
# Time has a significant negative effect on Btotal, suggesting that as Time increases, Btotal tends to decrease.
# FSM has a significant positive effect on Btotal, suggesting that higher FSM values are associated with higher Btotal. - aka if you're on FSM you have worse MH transitioning


# model considering the effect of Grades on SDQ over time
grades_model <- lmer(Btotal ~ Time * Eng + Time * Mat + (1 | ID), data = long_data)
summary(grades_model)
{
#   Linear mixed model fit by REML ['lmerMod']
# Formula: Btotal ~ Time * Eng + Time * Mat + (1 | ID)
#    Data: long_data
# 
# REML criterion at convergence: 37557.9
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -5.4386 -0.5707 -0.0603  0.4933  4.9998 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  ID       (Intercept) 5.408    2.326   
#  Residual             9.914    3.149   
# Number of obs: 6882, groups:  ID, 2294
# 
# Fixed effects:
#             Estimate Std. Error t value
# (Intercept) 41.00840    0.67523  60.732
# Time        -2.25233    0.27483  -8.195
# Eng         -0.65459    0.19362  -3.381
# Mat         -0.74688    0.17388  -4.295
# Time:Eng     0.39134    0.07760   5.043
# Time:Mat     0.10680    0.06875   1.553
# 
# Correlation of Fixed Effects:
#          (Intr) Time   Eng    Mat    Tm:Eng
# Time     -0.884                            
# Eng      -0.510  0.449                     
# Mat      -0.332  0.270 -0.630              
# Time:Eng  0.457 -0.502 -0.915  0.595       
# Time:Mat  0.295 -0.303  0.597 -0.918 -0.658
}
# Time: Significant negative effect on Btotal, indicating that Btotal tends to decrease over time.
# Eng and Mat: Both have significant negative effects on Btotal, indicating that higher values in these subjects are associated with lower Btotal.
# Time: Significant positive interaction effect, suggesting that the relationship between Eng and Btotal depends on Time. As Time and Eng increase together, Btotal tends to increase more than if they were considered separately.
# Time: Interaction effect is positive but not significant, indicating that the relationship between Mat and Btotal does not significantly change with Time.


# model considering the effect of all factors on SDQ over time
full_model <- lmer(Btotal ~ Time * AGtotal + Time * SCtotal + Time * LTtotal + Time * Ltotal + FSM + (1 | ID), data = long_data)
summary(full_model)
{
#   Linear mixed model fit by REML ['lmerMod']
# Formula: Btotal ~ Time * AGtotal + Time * SCtotal + Time * LTtotal + Time *  
#     Ltotal + FSM + (1 | ID)
#    Data: long_data
# 
# REML criterion at convergence: 36812.1
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -5.1528 -0.5692 -0.0363  0.5212  5.9990 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  ID       (Intercept) 3.745    1.935   
#  Residual             9.384    3.063   
# Number of obs: 6882, groups:  ID, 2294
# 
# Fixed effects:
#               Estimate Std. Error t value
# (Intercept)  33.899589   0.871232  38.910
# Time         -1.987804   0.359140  -5.535
# AGtotal       0.065225   0.036696   1.777
# SCtotal       0.018972   0.004061   4.672
# LTtotal      -0.179944   0.016011 -11.239
# Ltotal        0.083767   0.012801   6.544
# FSM           0.438387   0.140370   3.123
# Time:AGtotal  0.016512   0.016873   0.979
# Time:SCtotal  0.004549   0.001918   2.372
# Time:LTtotal  0.080970   0.007135  11.348
# Time:Ltotal   0.017217   0.008639   1.993
# 
# Correlation of Fixed Effects:
#             (Intr) Time   AGtotl SCtotl LTtotl Ltotal FSM    Tm:AGt Tm:SCt Tm:LTt
# Time        -0.895                                                               
# AGtotal     -0.645  0.658                                                        
# SCtotal     -0.320  0.283  0.104                                                 
# LTtotal     -0.570  0.540 -0.054  0.037                                          
# Ltotal      -0.272  0.259  0.087 -0.334  0.003                                   
# FSM         -0.206  0.013  0.007 -0.020  0.045 -0.020                            
# Time:AGtotl  0.583 -0.732 -0.905 -0.076  0.016 -0.072  0.002                     
# Time:SCtotl  0.236 -0.224 -0.078 -0.915  0.000  0.386  0.002  0.053              
# Time:LTtotl  0.464 -0.513  0.024 -0.005 -0.928  0.109 -0.042  0.019 -0.039       
# Time:Ltotal  0.186 -0.266 -0.062  0.260  0.011 -0.884  0.011  0.078 -0.350 -0.072
}
# Time: Significant negative effect on Btotal, indicating that as Time increases, Btotal tends to decrease.
# AGtotal, SCtotal, LTtotal, Ltotal: Each has its own significant effect on Btotal, and their interactions with Time suggest that their effects may vary depending on the level of Time.
# FSM: Significant positive effect on Btotal, suggesting that higher FSM values are associated with higher Btotal.
# Interpreting interactions (e.g., Time X AGtotal): The coefficient (e.g., Time = 0.016512) indicates how the effect of AGtotal on Btotal changes with Time. Here, it's positive, suggesting that as Time and AGtotal increase together, Btotal tends to increase more than expected from their individual effects.

```

```{r comparing the LME models}
# which model is best
# anova(model1, model2)
# A significant p-value (< 0.05) suggests that the more complex model (model1) fits significantly better than the simpler model (model2).
# AIC and BIC values  - lower values = better fitting model

# likelihood ratio test (will include AIC and BIC)
anova(full_model, base_model) # full is sig better

```

```{r normalising the data}
# normalising the data for the SEM
norm_data <- sum_data

# crating the normalisation function
normalize <- function(x) { (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE) }

# Identify columns to normalize (excluding ID)
cols_to_normalize <- setdiff(names(norm_data), "ID")

# Apply normalization to all relevant columns
norm_data[cols_to_normalize] <- lapply(norm_data[cols_to_normalize], normalize)

# Check if normalization is done correctly
summary(norm_data)

```

```{r SEM model}
# SEM models

#install.packages("lavaan")
library(lavaan)

# creating the model
crosslagged_model <- '
  # Regressions at each time point
  C1_Btotal ~ C1_AGtotal + C1_SCtotal + C1_LTtotal + C1_Ltotal + FSM
  C2_Btotal ~ C2_AGtotal + C2_SCtotal + C2_LTtotal + C2_Ltotal + FSM
  C3_Btotal ~ C3_AGtotal + C3_SCtotal + C3_LTtotal + C3_Ltotal + FSM
  
  # Auto-regressive paths
  C2_Btotal ~ C1_Btotal
  C3_Btotal ~ C2_Btotal
  
  # Cross-lagged paths (to see the influence of predictors over time)
  C2_AGtotal ~ C1_AGtotal
  C3_AGtotal ~ C2_AGtotal
  C2_SCtotal ~ C1_SCtotal
  C3_SCtotal ~ C2_SCtotal
  C2_LTtotal ~ C1_LTtotal
  C3_LTtotal ~ C2_LTtotal
  C2_Ltotal ~ C1_Ltotal
  C3_Ltotal ~ C2_Ltotal
'

# fitting the model made
cl_fit <- sem(crosslagged_model, data = norm_data, missing="fiml", fixed.x=FALSE)

# having a lil look-see what the ugly stats that are supposed to mean something 
summary(cl_fit, fit.measures=TRUE)

#install.packages("semPlot")
library(semPlot)

# plotting it all coz let's be real no one understands stats
node.labs1 <- c("C1 SDQ", "C1 Intelligence", "C1 School Concern", "C1 Liking Teachers", "C1 Lonliness", "FSM", 
                "C2 SDQ", "C2 Intelligence", "C2 School Concern", "C2 Liking Teachers", "C2 Lonliness", 
                "C3 SDQ", "C3 Intelligence", "C3 School Concern", "C3 Liking Teachers", "C3 Lonliness")

figure1 <- semPlot::semPaths(cl_fit, 
                             nCharNodes = 3, 
                             sizeMan = 5, 
                             residuals = TRUE, 
                             whatLabels = "est", 
                             width = 16, 
                             height = 5, 
                             normalize = FALSE) 
                             nodeLabels = node.labs1)

(figure1 <- qgraph::qgraph(figure1, title = "Model 1"))

semPlot::semCors(model1)


# note to self: FSM needs to be added to every time point in the cross lagged section
#               english and maths scores need to be added to the model
```



#### dubbed useless
```{r}
# the graveyard

T1 <- rep(1,nrow(sum_data))
T2 <- rep(2,nrow(sum_data))
T3 <- rep(3,nrow(sum_data))

testsum_data <- cbind(sum_data, T1, T2, T3)

ggplot(data = testsum_data, aes(x = T1, y = C1_Btotal)) + geom_point()

ggplot(data = testsum_data, aes(x = T2, y = C2_Btotal)) + geom_point()

# Reshape the data
testsum_long <- testsum_data %>%
  pivot_longer(cols = starts_with("T"), names_to = "Time", values_to = "TimeValue") %>%
  pivot_longer(cols = starts_with("C"), names_to = "BtotalType", values_to = "BtotalValue")

# Filter to match the correct pairs
testsum_long <- testsum_long %>%
  filter((Time == "T1" & BtotalType == "C1_Btotal") | (Time == "T2" & BtotalType == "C2_Btotal") | (Time == "T3" & BtotalType == "C3_Btotal"))

ggplot(data = testsum_long, aes(x = TimeValue, y = BtotalValue, color = Time, group = ID)) +
  geom_line() +
  labs(x = "Time", y = "Btotal Scores", color = "Time") +
  scale_color_manual(values = c("T1" = "blue", "T2" = "red")) +  # Customize line colors
  theme_minimal()
```


```{r}
# the cemetary
# linear mixed effects models
#"ID"  
#"Time"  
#"FSM" - fixed effect
#"Eng" - random effect
#"Mat" - random effect
#"Btotal" - random effect
#"AGtotal" - random effect
#"SCtotal" - random effect
#"LTtotal" - random effect
#"Ltotal"- random effect
# note: random intercepts go after the | and random slopes go after (1 +

#install.packages("lmerTest")
library(lmerTest)
model1 <- lmer(Btotal ~ 1 + Time + (Time|ID), data = long_data, REML = FALSE)
summary(model1)
{
#   Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite's
#   method [lmerModLmerTest]
# Formula: Btotal ~ 1 + Time + (Time | ID)
#    Data: long_data
# 
#      AIC      BIC   logLik deviance df.resid 
#  49672.3  49712.4 -24830.1  49660.3     5895 
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -1.8032 -0.8784  0.3137  0.8126  2.4229 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev. Corr 
#  ID       (Intercept)  64.154   8.010        
#           Time          8.051   2.837   -0.77
#  Residual             234.534  15.315        
# Number of obs: 5901, groups:  ID, 1967
# 
# Fixed effects:
#              Estimate Std. Error        df t value Pr(>|t|)    
# (Intercept)    6.8051     0.5575 1967.0829   12.21   <2e-16 ***
# Time           6.6627     0.2524 1967.1486   26.40   <2e-16 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#      (Intr)
# Time -0.910
}

# This LMM indicates that both Time (time) and the individual ID significantly influence Btotal (SDQ score). The negative correlation between random intercepts and slopes suggests that individuals with higher initial Btotal scores tend to have a smaller increase (or even a decrease) in Btotal over time.

# Overall, the model suggests that Btotal scores increase with time (Time), and there is significant variability both in the baseline scores (Intercept) and in how scores change over time (Time) across individuals (ID).

model2 <-  model2 <- lmer(Btotal ~ Time + FSM + 
               (1 + Time | ID) + 
               (1 + Time | Eng) + 
               (1 + Time | Mat) + 
               (1 + Time | AGtotal) + 
               (1 + Time | SCtotal) + 
               (1 + Time | LTtotal) + 
               (1 + Time | Ltotal), 
               data = long_data,
               REML = FALSE)
summary(model2)
{
# Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite's
#   method [lmerModLmerTest]
# Formula: Btotal ~ Time + FSM + (1 + Time | ID) + (1 + Time | Eng) + (1 +  
#     Time | Mat) + (1 + Time | AGtotal) + (1 + Time | SCtotal) +  
#     (1 + Time | LTtotal) + (1 + Time | Ltotal)
#    Data: long_data
# 
#      AIC      BIC   logLik deviance df.resid 
#  44895.3  45062.3 -22422.6  44845.3     5876 
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -3.4259 -0.1084  0.0627  0.4690  4.0145 
# 
# Random effects:
#  Groups   Name        Variance  Std.Dev. Corr 
#  ID       (Intercept)   0.42425  0.6513       
#           Time          3.29886  1.8163  -1.00
#  SCtotal  (Intercept)  15.37190  3.9207       
#           Time          2.04860  1.4313  -0.89
#  Ltotal   (Intercept)   4.19838  2.0490       
#           Time          0.23786  0.4877  1.00 
#  LTtotal  (Intercept)   0.17437  0.4176       
#           Time          0.14576  0.3818  1.00 
#  AGtotal  (Intercept)  50.82182  7.1289       
#           Time          2.31825  1.5226  -1.00
#  Mat      (Intercept)   0.00000  0.0000       
#           Time          0.21454  0.4632   NaN 
#  Eng      (Intercept)   0.00000  0.0000       
#           Time          0.06565  0.2562   NaN 
#  Residual             102.09846 10.1044       
# Number of obs: 5901, groups:  
# ID, 1967; SCtotal, 149; Ltotal, 51; LTtotal, 32; AGtotal, 18; Mat, 9; Eng, 8
# 
# Fixed effects:
#              Estimate Std. Error        df t value Pr(>|t|)    
# (Intercept)   34.4475     2.0882   26.4729  16.497 1.89e-15 ***
# Time          -0.7155     0.5997   24.5945  -1.193   0.2442    
# FSM           -0.6443     0.2802 1526.1509  -2.299   0.0216 *  
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#      (Intr) Time  
# Time -0.792       
# FSM  -0.143  0.012
# optimizer (nloptwrap) convergence code: 0 (OK)
# boundary (singular) fit: see help('isSingular')
}

isSingular(model2) # TRUE

# icba to deal with this now - i have to get rid of some multicollinearity that's begin created by the excessive inclusion fo intercepts and slopes but imma try to wrap my head around this later

```