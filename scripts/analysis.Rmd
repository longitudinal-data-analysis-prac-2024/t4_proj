---
title: "analysis.rmd"
author: "chrysie"
date: "2024-06-13"
output: html_document
---

```{r packages and libraries}
# always run this first

#install.packages("tidyverse")
library(tidyverse)

#install.packages("mice")
library(mice)

#install.packages("lmerTest")
library(lmerTest)

#install.packages("gridExtra")
library(gridExtra)

#install.packages("grid")
library(grid)

#install.packages("lavaan")
library(lavaan)

#install.packages("semPlot")
library(semPlot)

```

```{r set up}
# dealing with the NAs with multiple imputation
our_data <- read.csv("../data/our_data.csv", row.names = 1)

# trying to deal with the NAs with multiple imputation
#install.packages("mice")
library(mice)

# creating the imputation model
imp <- mice(our_data, method = rep("pmm", ncol(our_data)))

# making the imputed data set
new_data <- complete(imp)

# saving the new data frame because the imputation takes a hot minute so there's no need to re run it every time we open this script
write.csv(new_data, file = "../data/new_data.csv", row.names = FALSE)

```

```{r creating the summed data frame}
# calling the imputed data into the envrionment
new_data <- read.csv("../data/new_data.csv")

# summing the SDQ scores
  # getting each wave separated
cols_C1B <- new_data[, c("C1_B1", "C1_B2", "C1_B5", "C1_B10", "C1_B11", "C1_B12", "C1_B13", "C1_B14", "C1_B15", "C1_B16",
                               "C1_B17", "C1_B18", "C1_B19", "C1_B20", "C1_B21", "C1_B22", "C1_B23", "C1_B24", "C1_B25")]
                               
cols_C2B <- new_data[, c("C2_B1", "C2_B2", "C2_B5", "C2_B10", "C2_B11", "C2_B12", "C2_B13", "C2_B14", "C2_B15", "C2_B16",
                               "C2_B17", "C2_B18", "C2_B19", "C2_B20", "C2_B21", "C2_B22", "C2_B23", "C2_B24", "C2_B25")]

cols_C3B <- new_data[, c("C3_B1", "C3_B2", "C3_B5", "C3_B10", "C3_B11", "C3_B12", "C3_B13", "C3_B14", "C3_B15", "C3_B16",
                               "C3_B17", "C3_B18", "C3_B19", "C3_B20", "C3_B21", "C3_B22", "C3_B23", "C3_B24", "C3_B25")]

  # summing the scores for each wave
C1_Btotal <- rowSums(cols_C1B)
C2_Btotal <- rowSums(cols_C2B)
C3_Btotal <- rowSums(cols_C3B)


# summing the wentzel scores
# C1_AG1 to 4
cols_C1AG <- new_data[, c("C1_AG1", "C1_AG2", "C1_AG3", "C1_AG4")]
                  
cols_C2AG <- new_data[, c("C2_AG1", "C2_AG2", "C2_AG3", "C2_AG4")]

cols_C3AG <- new_data[, c("C3_AG1", "C3_AG2", "C3_AG3", "C3_AG4")]

  # summing the scores for each wave
C1_AGtotal <- rowSums(cols_C1AG)
C2_AGtotal <- rowSums(cols_C2AG)
C3_AGtotal <- rowSums(cols_C3AG)


# summing the SCQ
#C1_SConcern1 to 20

cols_C1SC <- new_data[, c("C1_SConcern1", "C1_SConcern2", "C1_SConcern3", "C1_SConcern4", "C1_SConcern5", "C1_SConcern6", "C1_SConcern7", "C1_SConcern8", "C1_SConcern9", "C1_SConcern10", "C1_SConcern11", "C1_SConcern12", "C1_SConcern13", "C1_SConcern14", "C1_SConcern15", "C1_SConcern16", "C1_SConcern17", "C1_SConcern18", "C1_SConcern19", "C1_SConcern20")]

cols_C2SC <- new_data[, c("C2_SConcern1", "C2_SConcern2", "C2_SConcern3", "C2_SConcern4", "C2_SConcern5", "C2_SConcern6", "C2_SConcern7", "C2_SConcern8", "C2_SConcern9", "C2_SConcern10", "C2_SConcern11", "C2_SConcern12", "C2_SConcern13", "C2_SConcern14", "C2_SConcern15", "C2_SConcern16", "C2_SConcern17", "C2_SConcern18", "C2_SConcern19", "C2_SConcern20")]

cols_C3SC <- new_data[, c("C3_SConcern1", "C3_SConcern2", "C3_SConcern3", "C3_SConcern4", "C3_SConcern5", "C3_SConcern6", "C3_SConcern7", "C3_SConcern8", "C3_SConcern9", "C3_SConcern10", "C3_SConcern11", "C3_SConcern12", "C3_SConcern13", "C3_SConcern14", "C3_SConcern15", "C3_SConcern16", "C3_SConcern17", "C3_SConcern18", "C3_SConcern19", "C3_SConcern20")]

  # summing the scores for each wave
C1_SCtotal <- rowSums(cols_C1SC)
C2_SCtotal <- rowSums(cols_C2SC)
C3_SCtotal <- rowSums(cols_C3SC)
 
  
#summing the liking teachers scores
#C1_LT1 to 10
cols_C1LT <- new_data[, c("C1_LT1", "C1_LT2", "C1_LT3", "C1_LT4", "C1_LT5", "C1_LT6", "C1_LT7", "C1_LT8", "C1_LT9", "C1_LT10")]
  
cols_C2LT <- new_data[, c("C2_LT1", "C2_LT2", "C2_LT3", "C2_LT4", "C2_LT5", "C2_LT7", "C2_LT6", "C2_LT8", "C2_LT9", "C2_LT10")]
  
cols_C3LT <- new_data[, c("C3_LT1", "C3_LT2", "C3_LT3", "C3_LT4", "C3_LT5", "C3_LT6", "C3_LT7", "C3_LT8", "C3_LT9", "C3_LT10")]

  # summing the scores for each wave
C1_LTtotal <- rowSums(cols_C1LT)
C2_LTtotal <- rowSums(cols_C2LT)
C3_LTtotal <- rowSums(cols_C3LT)


# summing the lonliness scores
#C1_L1 to 15
cols_C1L <- new_data[, c("C1_L1", "C1_L2", "C1_L3", "C1_L4", "C1_L5","C1_L6", "C1_L7","C1_L8","C1_L9", "C1_L10", "C1_L11", "C1_L12","C1_L13","C1_L14", "C1_L15")]

cols_C2L <- new_data[, c("C2_L1","C2_L2", "C2_L6", "C2_L7", "C2_L11", "C2_L14","C2_L15")]

cols_C3L <- new_data[, c("C3_L1", "C3_L2", "C3_L6", "C3_L7", "C3_L11", "C3_L14",   "C3_L15")]
  
  # summing the scores for each wave
C1_Ltotal <- rowSums(cols_C1L)
C2_Ltotal <- rowSums(cols_C2L)
C3_Ltotal <- rowSums(cols_C3L)


sum_data <- tibble(
  ID = new_data$ID,
  FSM = new_data$FSM,
  C1_Eng = new_data$KS2Eng,
  C1_Mat = new_data$KS2Mat,
  C2_Eng = new_data$KS2Eng,
  C2_Mat = new_data$KS2Mat,
  C3_Eng = new_data$KS3Eng,
  C3_Mat = new_data$KS3Mat,
  C1_Btotal = C1_Btotal,
  C2_Btotal = C2_Btotal,
  C3_Btotal = C3_Btotal,
  C1_AGtotal = C1_AGtotal,
  C2_AGtotal = C2_AGtotal,
  C3_AGtotal = C3_AGtotal,
  C1_SCtotal = C1_SCtotal,
  C2_SCtotal = C2_SCtotal,
  C3_SCtotal = C3_SCtotal,
  C1_LTtotal = C1_LTtotal,
  C2_LTtotal = C2_LTtotal,
  C3_LTtotal = C3_LTtotal,
  C1_Ltotal = C1_Ltotal,
  C2_Ltotal = C2_Ltotal,
  C3_Ltotal = C3_Ltotal
)


# making a lil .csv so the project can be run from here on wards - it's like a game checkpoint
write.csv(sum_data, file = "../data/sum_data.csv", row.names = FALSE)

```

```{r detol wipes and antibacterial spray}
# all objects in the global environment
all_objects <- ls()

# keeping only the two dfs
objects_to_keep <- c("new_data", "sum_data")
objects_to_remove <- setdiff(all_objects, objects_to_keep)

# bibbity-bobbity-boop!
rm(list = objects_to_remove)
rm(all_objects, objects_to_keep, objects_to_remove)
cat("\014")
```

```{r getting the data into long format}
library(tidyverse)

# converting the df to long format
long_data <- sum_data %>%
  pivot_longer(
    cols = matches("C[123]_"),
    names_to = c("timepoint", "measure"),
    names_pattern = "C(\\d+)_(.*)"
  ) %>%
  pivot_wider(
    names_from = measure,
    values_from = value
  ) %>%
  rename(Time = timepoint) %>%
  mutate(Time = factor(Time, levels = c("1", "2", "3"))) %>%
  arrange(ID, Time) %>%
  relocate(Time, .after = ID) %>%
  mutate(Time = as.numeric(Time)) %>%
  mutate_at(vars(ends_with("total")), ~replace_na(., 0)) %>%
  mutate_at(vars(FSM, Eng, Mat), ~replace_na(.,0))

#  long format checkpoint
write.csv(long_data, file = "../data/long_data.csv", row.names = FALSE)

```

```{r linear-mixed effects models}
# take 2 on lme models
# note: random intercepts go after the | and random slopes go after (1 +
#install.packages("lmerTest")
library(lmerTest)

# call if hasn't already been loaded
#long_data <- read.csv("../data/long_data.csv")

# Model with random intercept only
base_model <- lmerTest::lmer(Btotal ~ Time + (1 | ID), data = long_data)
summary(base_model)
{
# Linear mixed model fit by REML. t-tests use Satterthwaite's method [
# lmerModLmerTest]
# Formula: Btotal ~ Time + (1 | ID)
#    Data: long_data
# 
# REML criterion at convergence: 37659.5
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -5.3393 -0.5772 -0.0595  0.5029  4.9919 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  ID       (Intercept)  5.478   2.341   
#  Residual             10.086   3.176   
# Number of obs: 6882, groups:  ID, 2294
# 
# Fixed effects:
#               Estimate Std. Error         df t value Pr(>|t|)    
# (Intercept)   35.16274    0.11246 6854.81436 312.670  < 2e-16 ***
# Time          -0.18112    0.04689 4587.00023  -3.863 0.000114 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#      (Intr)
# Time -0.834
}
# The model indicates that Btotal decreases slightly over time, and this effect is statistically significant.
# There is significant variability in the intercepts across different individuals (ID), suggesting that individual differences account for a substantial portion of the variance in Btotal.
# The high t values for both the intercept and the Time coefficient suggest that these fixed effects are very significant predictors of Btotal.


# model considering the effect of FSMs on SDQ over time
fixed_model <- lmerTest::lmer(Btotal ~ Time + FSM + (1 | ID), data = long_data)
summary(fixed_model)
{
# Linear mixed model fit by REML. t-tests use Satterthwaite's method [
# lmerModLmerTest]
# Formula: Btotal ~ Time + FSM + (1 | ID)
#    Data: long_data
# 
# REML criterion at convergence: 37639.6
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -5.3205 -0.5726 -0.0644  0.4937  5.0201 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  ID       (Intercept)  5.399   2.324   
#  Residual             10.086   3.176   
# Number of obs: 6882, groups:  ID, 2294
# 
# Fixed effects:
#               Estimate Std. Error         df t value Pr(>|t|)    
# (Intercept)   34.28607    0.21876 3355.06606 156.727  < 2e-16 ***
# Time          -0.18112    0.04689 4587.00001  -3.863 0.000114 ***
# FSM            0.73748    0.15793 2291.99998   4.670 3.19e-06 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#      (Intr) Time  
# Time -0.429       
# FSM  -0.858  0.000
}
# The intercept (34.28607) represents the estimated value of Btotal when Time and FSM are both zero.
# Time has a significant negative effect on Btotal, suggesting that as Time increases, Btotal tends to decrease.
# FSM has a significant positive effect on Btotal, suggesting that higher FSM values are associated with higher Btotal. - aka if you're on FSM you have worse MH transitioning


# model considering the effect of Grades on SDQ over time
grades_model <- lmerTest::lmer(Btotal ~ Time * Eng + Time * Mat + (1 | ID), data = long_data)
summary(grades_model)
{
# Linear mixed model fit by REML. t-tests use Satterthwaite's method [
# lmerModLmerTest]
# Formula: Btotal ~ Time * Eng + Time * Mat + (1 | ID)
#    Data: long_data
# 
# REML criterion at convergence: 37557.9
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -5.4386 -0.5707 -0.0603  0.4933  4.9998 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  ID       (Intercept) 5.408    2.326   
#  Residual             9.914    3.149   
# Number of obs: 6882, groups:  ID, 2294
# 
# Fixed effects:
#               Estimate Std. Error         df t value Pr(>|t|)    
# (Intercept)   41.00840    0.67523 6776.74018  60.732  < 2e-16 ***
# Time          -2.25233    0.27483 5096.58085  -8.195 3.13e-16 ***
# Eng           -0.65459    0.19362 6802.52017  -3.381 0.000727 ***
# Mat           -0.74688    0.17388 6831.93097  -4.295 1.77e-05 ***
# Time:Eng       0.39134    0.07760 5877.89587   5.043 4.72e-07 ***
# Time:Mat       0.10680    0.06875 5918.33771   1.553 0.120403    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#          (Intr) Time   Eng    Mat    Tm:Eng
# Time     -0.884                            
# Eng      -0.510  0.449                     
# Mat      -0.332  0.270 -0.630              
# Time:Eng  0.457 -0.502 -0.915  0.595       
# Time:Mat  0.295 -0.303  0.597 -0.918 -0.658
}
# Time: Significant negative effect on Btotal, indicating that Btotal tends to decrease over time.
# Eng and Mat: Both have significant negative effects on Btotal, indicating that higher values in these subjects are associated with lower Btotal.
# Time: Significant positive interaction effect, suggesting that the relationship between Eng and Btotal depends on Time. As Time and Eng increase together, Btotal tends to increase more than if they were considered separately.
# Time: Interaction effect is positive but not significant, indicating that the relationship between Mat and Btotal does not significantly change with Time.


# model considering the effect of all factors on SDQ over time
full_model <- lmerTest::lmer(Btotal ~ Time * AGtotal + Time * SCtotal + Time * LTtotal + Time * Ltotal + FSM + (1 | ID), data = long_data)
summary(full_model)
{
# Linear mixed model fit by REML. t-tests use Satterthwaite's method [
# lmerModLmerTest]
# Formula: Btotal ~ Time * AGtotal + Time * SCtotal + Time * LTtotal + Time *  
#     Ltotal + FSM + (1 | ID)
#    Data: long_data
# 
# REML criterion at convergence: 36812.1
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -5.1528 -0.5692 -0.0363  0.5212  5.9990 
# 
# Random effects:
#  Groups   Name        Variance Std.Dev.
#  ID       (Intercept) 3.745    1.935   
#  Residual             9.384    3.063   
# Number of obs: 6882, groups:  ID, 2294
# 
# Fixed effects:
#                Estimate Std. Error         df t value Pr(>|t|)    
# (Intercept)   3.390e+01  8.712e-01  6.414e+03  38.910  < 2e-16 ***
# Time         -1.988e+00  3.591e-01  5.871e+03  -5.535 3.25e-08 ***
# AGtotal       6.523e-02  3.670e-02  6.082e+03   1.777  0.07554 .  
# SCtotal       1.897e-02  4.061e-03  6.027e+03   4.672 3.05e-06 ***
# LTtotal      -1.799e-01  1.601e-02  6.422e+03 -11.239  < 2e-16 ***
# Ltotal        8.377e-02  1.280e-02  5.837e+03   6.544 6.52e-11 ***
# FSM           4.384e-01  1.404e-01  2.272e+03   3.123  0.00181 ** 
# Time:AGtotal  1.651e-02  1.687e-02  5.788e+03   0.979  0.32781    
# Time:SCtotal  4.549e-03  1.918e-03  5.853e+03   2.372  0.01771 *  
# Time:LTtotal  8.097e-02  7.135e-03  6.191e+03  11.348  < 2e-16 ***
# Time:Ltotal   1.722e-02  8.639e-03  6.257e+03   1.993  0.04631 *  
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#             (Intr) Time   AGtotl SCtotl LTtotl Ltotal FSM    Tm:AGt Tm:SCt
# Time        -0.895                                                        
# AGtotal     -0.645  0.658                                                 
# SCtotal     -0.320  0.283  0.104                                          
# LTtotal     -0.570  0.540 -0.054  0.037                                   
# Ltotal      -0.272  0.259  0.087 -0.334  0.003                            
# FSM         -0.206  0.013  0.007 -0.020  0.045 -0.020                     
# Time:AGtotl  0.583 -0.732 -0.905 -0.076  0.016 -0.072  0.002              
# Time:SCtotl  0.236 -0.224 -0.078 -0.915  0.000  0.386  0.002  0.053       
# Time:LTtotl  0.464 -0.513  0.024 -0.005 -0.928  0.109 -0.042  0.019 -0.039
# Time:Ltotal  0.186 -0.266 -0.062  0.260  0.011 -0.884  0.011  0.078 -0.350
#             Tm:LTt
# Time              
# AGtotal           
# SCtotal           
# LTtotal           
# Ltotal            
# FSM               
# Time:AGtotl       
# Time:SCtotl       
# Time:LTtotl       
# Time:Ltotal -0.072
}
# Time: Significant negative effect on Btotal, indicating that as Time increases, Btotal tends to decrease.
# AGtotal, SCtotal, LTtotal, Ltotal: Each has its own significant effect on Btotal, and their interactions with Time suggest that their effects may vary depending on the level of Time.
# FSM: Significant positive effect on Btotal, suggesting that higher FSM values are associated with higher Btotal.
# Interpreting interactions (e.g., Time X AGtotal): The coefficient (e.g., Time = 0.016512) indicates how the effect of AGtotal on Btotal changes with Time. Here, it's positive, suggesting that as Time and AGtotal increase together, Btotal tends to increase more than expected from their individual effects.

```

```{r visualsing the lme models}
# imma visualise a little coz that's gonna help me ac understand the onslaught of numbers the lmer have given me
library(ggplot2)

# colour-blind friendly colour pallet
#"hotpink3", "olivedrab3", "maroon4", "gold", "cadetblue3", "mediumorchid3", "darkolivegreen"

# visual for the base model
(base_mod_fig <- long_data %>%
  group_by(Time) %>%
  mutate(tmean = mean(Btotal)) %>%
  ggplot(mapping = aes(x = Time, y = tmean)) +
  geom_line(color = "cadetblue3", linewidth = 1.5) +  
  labs(title = "SQD Score over Time",
       y = "SDQ score") +
  scale_x_continuous(breaks = c(1, 2, 3)) +
  theme(plot.title = element_text(hjust = 0.4)))
# okay so overall, the average SDQ goes down from primary to secondary school and that's supported by the model's outcomes

# saving it
ggsave(filename = "../output/base_mod_fig.jpg", plot = base_mod_fig)


# visual for the FSM model
(fsm_mod_fig <- long_data %>%
  group_by(Time, FSM) %>%
  mutate(tmean = mean(Btotal)) %>%
  ggplot(mapping = aes(x = Time, y = tmean, colour = factor(FSM))) +
  geom_line(linewidth = 1.5) +  
  labs(title = "SDQ Score over Time depending on FSM Status",
       y = "SDQ score") +
  scale_x_continuous(breaks = c(1, 2, 3)) +
  theme(plot.title = element_text(hjust = 0.4)) +
  scale_colour_manual(
    values = c("1" = "cadetblue3", "2" = "mediumorchid3"), 
    name = "FSM Status", 
    labels = c("Not on FSMs", "On FSMs")))
# okay so for those with FSM, aka lower SES, the decline in SDQ is much more steep with the transisiton between primary and secondary school

# saving it
ggsave(filename = "../output/fsm_mod_fig.jpg", plot = fsm_mod_fig)


# visual for the grades model
library(gridExtra)

# English scores
plot_eng <- ggplot(long_data, aes(x = Eng, y = Btotal)) +
  geom_point() +                      
  geom_smooth(method = "lm", se = FALSE, color = "hotpink3") +  
  labs(title = "SDQ Score and Subject Grades over Time",
       x = "English Scores",
       y = "SDQ Scores") +      
  theme_minimal() +            
  facet_wrap(~ Time, labeller = labeller(Time = c("1" = "Time Point 1 - End of Yr 6", 
                                                  "2" = "Time Point 2 - Beginning of Yr 7", 
                                                  "3" = "Time Point 3 - End of Yr 7"))) +  
  theme(aspect.ratio = 0.5, plot.title = element_text(hjust = 0.4)) +
  coord_fixed(ratio = 0.1)

# maths scores
plot_mat <- ggplot(long_data, aes(x = Mat, y = Btotal)) +
  geom_point() +                      
  geom_smooth(method = "lm", se = FALSE, color = "hotpink3") +  
  labs(x = "Maths Scores",
       y = "SDQ Scores") +      
  theme_minimal() +            
  facet_wrap(~ Time, labeller = labeller(Time = c("1" = "Time Point 1 - End of Yr 6", 
                                                  "2" = "Time Point 2 - Beginning of Yr 7", 
                                                  "3" = "Time Point 3 - End of Yr 7"))) +  
  theme(aspect.ratio = 0.5, plot.title = element_text(hjust = 0.4)) +
  coord_fixed(ratio = 0.1)

# combine plots into one grid with 2 rows
(grades_plot <- grid.arrange(plot_eng, plot_mat, nrow = 2))

# saving it
ggsave(filename = "../output/grades_plot.jpg", plot = grades_plot, width = 11, height = 7, units = "in")


# visualisation for all variables
# wentzel's intelligence
plot_wen <- ggplot(long_data, aes(x = AGtotal, y = Btotal)) +
  geom_point() +                      
  geom_smooth(method = "lm", se = FALSE, color = "hotpink3") +  
  labs(x = "Wentzel's Intelligence Scores",
       y = "SDQ Scores") +  
  theme(plot.title = element_text(size = 100)) +
  theme_minimal() +            
  facet_wrap(~ Time, labeller = labeller(Time = c("1" = "Time Point 1 - End of Yr 6", 
                                                  "2" = "Time Point 2 - Beginning of Yr 7", 
                                                  "3" = "Time Point 3 - End of Yr 7"))) +  
  theme(plot.title = element_text(hjust = 0.5), strip.text = element_text(size = 20),
        axis.text = element_text(size = 15), axis.title = element_text(size = 20))

# school concern
plot_sc <- ggplot(long_data, aes(x = SCtotal, y = Btotal)) +
  geom_point() +                      
  geom_smooth(method = "lm", se = FALSE, color = "hotpink3") +  
  labs(x = "School Concern Scores",
       y = "SDQ Scores") +      
  theme_minimal() +            
  facet_wrap(~ Time, labeller = labeller(Time = c("1" = "Time Point 1 - End of Yr 6", 
                                                  "2" = "Time Point 2 - Beginning of Yr 7", 
                                                  "3" = "Time Point 3 - End of Yr 7"))) +  
  theme(plot.title = element_text(hjust = 0.4), strip.text = element_text(size = 20),
        axis.text = element_text(size = 15), axis.title = element_text(size = 20))

# liking teachers
plot_lt <- ggplot(long_data, aes(x = LTtotal, y = Btotal)) +
  geom_point() +                      
  geom_smooth(method = "lm", se = FALSE, color = "hotpink3") +  
  labs(x = "Liking Teachers Scores",
       y = "SDQ Scores") +      
  theme_minimal() +            
  facet_wrap(~ Time, labeller = labeller(Time = c("1" = "Time Point 1 - End of Yr 6", 
                                                  "2" = "Time Point 2 - Beginning of Yr 7", 
                                                  "3" = "Time Point 3 - End of Yr 7"))) +  
  theme(plot.title = element_text(hjust = 0.4), strip.text = element_text(size = 20),
        axis.text = element_text(size = 15), axis.title = element_text(size = 20))

# lonliness
plot_lon <- ggplot(long_data, aes(x = Ltotal, y = Btotal)) +
  geom_point() +                      
  geom_smooth(method = "lm", se = FALSE, color = "hotpink3") +  
  labs(x = "Lonliness Scores",
       y = "SDQ Scores") +      
  theme_minimal() +            
  facet_wrap(~ Time, scales = "free_x", labeller = labeller(Time = c("1" = "Time Point 1 - End of Yr 6", 
                                                  "2" = "Time Point 2 - Beginning of Yr 7", 
                                                  "3" = "Time Point 3 - End of Yr 7"))) +  
  theme(plot.title = element_text(hjust = 0.4), strip.text = element_text(size = 20),
        axis.text = element_text(size = 15), axis.title = element_text(size = 20))

# combine plots into one grid 
(vars_plot <- grid.arrange(plot_wen, plot_sc, plot_lt, plot_lon, nrow = 4, top = textGrob("SDQ Score and Psychosocial Vairables over Time", gp = gpar(fontsize = 30))))

# saving it
ggsave(filename = "../output/vars_plot.jpg", plot = vars_plot, width = 20, height = 15, units = "in")

```

```{r lme "reporting-stats" data frame}
# getting all the reporting stats so they can be put into the read me

# creating a function to extract the required values from a model summary
extract_model_info <- function(model) {
  summary_model <- summary(model)
  coefs <- summary_model$coefficients
  
  # Extracting relevant values for each effect
  beta <- coefs[, 1]
  df <- coefs[, 3]
  t_value <- coefs[, 4]
  p_value <- coefs[, 5]
  significant <- p_value < 0.05
  
  # Combine into a data frame
  model_info <- data.frame(
    Effect = rownames(coefs),
    Beta = beta,
    DF = df,
    T_Value = t_value,
    P_Value = p_value,
    Significant = significant
  )
  
  return(model_info)
}

# extracting information from each model
base_model_info <- extract_model_info(base_model)
grades_model_info <- extract_model_info(grades_model)
full_model_info <- extract_model_info(full_model)

# Adding a column to indicate the model
base_model_info$Model <- "base_model"
grades_model_info$Model <- "grades_model"
full_model_info$Model <- "full_model"

# Combining the information into a single data frame
lme_stats <- rbind(base_model_info, grades_model_info, full_model_info)

# Reordering columns for better readability
lme_stats <- lme_stats[, c("Model", "Effect", "Beta", "DF", "T_Value", "P_Value", "Significant")]

# lme stats checkpoint
write.csv(lme_stats, file = "../output/lme_stats.csv", row.names = FALSE)

```


```{r comparing the LME models}
# which model is best
# anova(model1, model2)
# A significant p-value (< 0.05) suggests that the more complex model (model1) fits significantly better than the simpler model (model2).
# AIC and BIC values  - lower values = better fitting model

# likelihood ratio test (will include AIC and BIC)
anova(full_model, base_model) # full is sig better - expected tbh

```


```{r normalising the data}
# normalising the data for the SEM

# call if hasn't already been loaded
sum_data <- read.csv("../data/sum_data.csv")

norm_data <- sum_data

# crating the normalisation function
normalize <- function(x) { (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE) }

# Identify columns to normalize (excluding ID)
cols_to_normalize <- setdiff(names(norm_data), "ID")

# Apply normalization to all relevant columns
norm_data[cols_to_normalize] <- lapply(norm_data[cols_to_normalize], normalize)

# Check if normalization is done correctly
summary(norm_data)

norm_data <- norm_data %>%
  rename("T1_Eng" = "C1_Eng", "T1_Mat" = "C1_Mat", "T2_Eng" = "C2_Eng", "T2_Mat" = "C2_Mat", "T3_Eng" = "C3_Eng",
         "T3_Mat" = "C3_Mat", "T1_SQD" = "C1_Btotal", "T2_SQD" = "C2_Btotal", "T3_SQD" = "C3_Btotal",
         "T1_Wen" = "C1_AGtotal", "T2_Wen" = "C2_AGtotal", "T3_Wen" = "C3_AGtotal", "T1_SC" = "C1_SCtotal",
         "T2_SC" = "C2_SCtotal", "T3_SC" = "C3_SCtotal", "T1_LT" = "C1_LTtotal", "T2_LT" = "C2_LTtotal",
         "T3_LT" = "C3_LTtotal", "T1_Lon" = "C1_Ltotal", "T2_Lon" = "C2_Ltotal", "T3_Lon" = "C3_Ltotal")

```


```{r SEM model 1}
# SEM models

#install.packages("lavaan")
library(lavaan)

reg_model <- '
  # Regressions at each time point
  T1_SQD ~ T1_Wen + T1_SC + T1_LT + T1_Lon + FSM + T1_Eng + T1_Mat
  T2_SQD ~ T2_Wen + T2_SC + T2_LT + T2_Lon + FSM
  T3_SQD ~ T3_Wen + T3_SC + T3_LT + T3_Lon + FSM + T3_Eng + T3_Mat
'

reg_fit <- sem(reg_model, data = norm_data, missing = "fiml", fixed.x = FALSE)
summary(reg_fit, fit.measures = TRUE)
{
#   lavaan 0.6-18 ended normally after 41 iterations
# 
#   Estimator                                         ML
#   Optimization method                           NLMINB
#   Number of model parameters                       198
# 
#   Number of observations                          2294
#   Number of missing patterns                         1
# 
# Model Test User Model:
#                                                       
#   Test statistic                               203.709
#   Degrees of freedom                                32
#   P-value (Chi-square)                           0.000
# 
# Model Test Baseline Model:
# 
#   Test statistic                              2066.271
#   Degrees of freedom                                54
#   P-value                                        0.000
# 
# User Model versus Baseline Model:
# 
#   Comparative Fit Index (CFI)                    0.915
#   Tucker-Lewis Index (TLI)                       0.856
#                                                       
#   Robust Comparative Fit Index (CFI)             0.915
#   Robust Tucker-Lewis Index (TLI)                0.856
# 
# Loglikelihood and Information Criteria:
# 
#   Loglikelihood user model (H0)             -59149.876
#   Loglikelihood unrestricted model (H1)     -59048.021
#                                                       
#   Akaike (AIC)                              118695.752
#   Bayesian (BIC)                            119831.887
#   Sample-size adjusted Bayesian (SABIC)     119202.804
# 
# Root Mean Square Error of Approximation:
# 
#   RMSEA                                          0.048
#   90 Percent confidence interval - lower         0.042
#   90 Percent confidence interval - upper         0.055
#   P-value H_0: RMSEA <= 0.050                    0.651
#   P-value H_0: RMSEA >= 0.080                    0.000
#                                                       
#   Robust RMSEA                                   0.048
#   90 Percent confidence interval - lower         0.042
#   90 Percent confidence interval - upper         0.055
#   P-value H_0: Robust RMSEA <= 0.050             0.667
#   P-value H_0: Robust RMSEA >= 0.080             0.000
# 
# Standardized Root Mean Square Residual:
# 
#   SRMR                                           0.021
# 
# Parameter Estimates:
# 
#   Standard errors                             Standard
#   Information                                 Observed
#   Observed information based on                Hessian
# 
# Regressions:
#                    Estimate  Std.Err  z-value  P(>|z|)
#   T1_SQD ~                                            
#     T1_Wen            0.079    0.018    4.442    0.000
#     T1_SC             0.165    0.018    8.939    0.000
#     T1_LT            -0.136    0.018   -7.668    0.000
#     T1_Lon            0.349    0.019   18.612    0.000
#     FSM               0.035    0.018    1.939    0.053
#     T1_Eng           -0.063    0.022   -2.909    0.004
#     T1_Mat            0.012    0.022    0.554    0.580
#   T2_SQD ~                                            
#     T2_Wen            0.072    0.019    3.769    0.000
#     T2_SC             0.240    0.020   11.981    0.000
#     T2_LT            -0.096    0.019   -4.965    0.000
#     T2_Lon            0.059    0.020    2.899    0.004
#     FSM               0.030    0.020    1.509    0.131
#   T3_SQD ~                                            
#     T3_Wen            0.074    0.019    3.830    0.000
#     T3_SC             0.182    0.020    9.267    0.000
#     T3_LT             0.058    0.020    2.994    0.003
#     T3_Lon            0.197    0.020    9.985    0.000
#     FSM               0.070    0.020    3.520    0.000
#     T3_Eng            0.129    0.023    5.675    0.000
#     T3_Mat           -0.036    0.023   -1.559    0.119
# 
# Covariances:
#                    Estimate  Std.Err  z-value  P(>|z|)
#  .T1_SQD ~~                                           
#    .T2_SQD            0.198    0.017   11.361    0.000
#    .T3_SQD            0.228    0.018   12.920    0.000
#  .T2_SQD ~~                                           
#    .T3_SQD            0.304    0.020   15.454    0.000
#   T1_Wen ~~                                           
#     T1_SC            -0.209    0.021   -9.814    0.000
#     T1_LT             0.141    0.021    6.682    0.000
#     T1_Lon           -0.214    0.021  -10.018    0.000
#     FSM              -0.057    0.021   -2.740    0.006
#     T1_Eng            0.181    0.021    8.514    0.000
#     T1_Mat            0.144    0.021    6.848    0.000
#     T2_Wen            0.376    0.022   16.865    0.000
#     T2_SC            -0.106    0.021   -5.060    0.000
#     T2_LT             0.161    0.021    7.606    0.000
#     T2_Lon           -0.127    0.021   -6.048    0.000
#     T3_Wen            0.245    0.021   11.417    0.000
#     T3_SC            -0.065    0.021   -3.088    0.002
#     T3_LT            -0.114    0.021   -5.419    0.000
#     T3_Lon           -0.076    0.021   -3.616    0.000
#     T3_Eng            0.137    0.021    6.487    0.000
#     T3_Mat            0.125    0.021    5.920    0.000
#   T1_SC ~~                                            
#     T1_LT            -0.181    0.021   -8.534    0.000
#     T1_Lon            0.332    0.022   15.084    0.000
#     FSM               0.106    0.021    5.070    0.000
#     T1_Eng           -0.160    0.021   -7.590    0.000
#     T1_Mat           -0.209    0.021   -9.811    0.000
#     T2_Wen           -0.037    0.021   -1.766    0.077
#     T2_SC             0.419    0.023   18.525    0.000
#     T2_LT            -0.213    0.021   -9.999    0.000
#     T2_Lon            0.206    0.021    9.659    0.000
#     T3_Wen           -0.036    0.021   -1.740    0.082
#     T3_SC             0.356    0.022   16.068    0.000
#     T3_LT             0.105    0.021    4.981    0.000
#     T3_Lon            0.246    0.021   11.428    0.000
#     T3_Eng           -0.136    0.021   -6.452    0.000
#     T3_Mat           -0.163    0.021   -7.730    0.000
#   T1_LT ~~                                            
#     T1_Lon           -0.273    0.022  -12.617    0.000
#     FSM              -0.103    0.021   -4.902    0.000
#     T1_Eng            0.147    0.021    6.973    0.000
#     T1_Mat            0.180    0.021    8.507    0.000
#     T2_Wen            0.066    0.021    3.152    0.002
#     T2_SC            -0.131    0.021   -6.235    0.000
#     T2_LT             0.173    0.021    8.178    0.000
#     T2_Lon           -0.091    0.021   -4.323    0.000
#     T3_Wen            0.031    0.021    1.496    0.135
#     T3_SC            -0.115    0.021   -5.486    0.000
#     T3_LT            -0.178    0.021   -8.377    0.000
#     T3_Lon           -0.122    0.021   -5.806    0.000
#     T3_Eng            0.130    0.021    6.199    0.000
#     T3_Mat            0.147    0.021    6.959    0.000
#   T1_Lon ~~                                           
#     FSM               0.107    0.021    5.087    0.000
#     T1_Eng           -0.118    0.021   -5.609    0.000
#     T1_Mat           -0.208    0.021   -9.753    0.000
#     T2_Wen           -0.127    0.021   -6.031    0.000
#     T2_SC             0.273    0.022   12.599    0.000
#     T2_LT            -0.240    0.021  -11.175    0.000
#     T2_Lon            0.296    0.022   13.584    0.000
#     T3_Wen           -0.072    0.021   -3.456    0.001
#     T3_SC             0.293    0.022   13.489    0.000
#     T3_LT             0.176    0.021    8.317    0.000
#     T3_Lon            0.370    0.022   16.638    0.000
#     T3_Eng           -0.130    0.021   -6.182    0.000
#     T3_Mat           -0.177    0.021   -8.336    0.000
#   FSM ~~                                              
#     T1_Eng           -0.173    0.021   -8.161    0.000
#     T1_Mat           -0.203    0.021   -9.519    0.000
#     T2_Wen           -0.036    0.021   -1.730    0.084
#     T2_SC             0.054    0.021    2.599    0.009
#     T2_LT            -0.073    0.021   -3.510    0.000
#     T2_Lon            0.025    0.021    1.187    0.235
#     T3_Wen           -0.034    0.021   -1.646    0.100
#     T3_SC             0.045    0.021    2.134    0.033
#     T3_LT             0.046    0.021    2.210    0.027
#     T3_Lon            0.011    0.021    0.549    0.583
#     T3_Eng           -0.175    0.021   -8.239    0.000
#     T3_Mat           -0.191    0.021   -9.001    0.000
#   T1_Eng ~~                                           
#     T1_Mat            0.616    0.025   25.130    0.000
#     T2_Wen            0.005    0.021    0.255    0.798
#     T2_SC            -0.138    0.021   -6.561    0.000
#     T2_LT             0.123    0.021    5.861    0.000
#     T2_Lon           -0.048    0.021   -2.303    0.021
#     T3_Wen            0.036    0.021    1.733    0.083
#     T3_SC            -0.117    0.021   -5.564    0.000
#     T3_LT            -0.070    0.021   -3.334    0.001
#     T3_Lon           -0.103    0.021   -4.908    0.000
#     T3_Eng            0.630    0.025   25.538    0.000
#     T3_Mat            0.504    0.023   21.565    0.000
#   T1_Mat ~~                                           
#     T2_Wen            0.011    0.021    0.522    0.602
#     T2_SC            -0.199    0.021   -9.338    0.000
#     T2_LT             0.156    0.021    7.370    0.000
#     T2_Lon           -0.079    0.021   -3.780    0.000
#     T3_Wen            0.043    0.021    2.074    0.038
#     T3_SC            -0.193    0.021   -9.077    0.000
#     T3_LT            -0.035    0.021   -1.668    0.095
#     T3_Lon           -0.131    0.021   -6.235    0.000
#     T3_Eng            0.548    0.024   23.016    0.000
#     T3_Mat            0.651    0.025   26.131    0.000
#   T2_Wen ~~                                           
#     T2_SC            -0.055    0.021   -2.655    0.008
#     T2_LT             0.214    0.021   10.005    0.000
#     T2_Lon           -0.169    0.021   -8.000    0.000
#     T3_Wen            0.467    0.023   20.284    0.000
#     T3_SC            -0.063    0.021   -3.022    0.003
#     T3_LT            -0.202    0.021   -9.505    0.000
#     T3_Lon           -0.118    0.021   -5.625    0.000
#     T3_Eng            0.038    0.021    1.804    0.071
#     T3_Mat            0.037    0.021    1.759    0.079
#   T2_SC ~~                                            
#     T2_LT            -0.172    0.021   -8.110    0.000
#     T2_Lon            0.375    0.022   16.813    0.000
#     T3_Wen           -0.050    0.021   -2.393    0.017
#     T3_SC             0.509    0.023   21.722    0.000
#     T3_LT             0.101    0.021    4.814    0.000
#     T3_Lon            0.305    0.022   13.964    0.000
#     T3_Eng           -0.117    0.021   -5.586    0.000
#     T3_Mat           -0.188    0.021   -8.869    0.000
#   T2_LT ~~                                            
#     T2_Lon           -0.240    0.021  -11.184    0.000
#     T3_Wen            0.135    0.021    6.417    0.000
#     T3_SC            -0.139    0.021   -6.597    0.000
#     T3_LT            -0.455    0.023  -19.826    0.000
#     T3_Lon           -0.190    0.021   -8.937    0.000
#     T3_Eng            0.138    0.021    6.529    0.000
#     T3_Mat            0.124    0.021    5.876    0.000
#   T2_Lon ~~                                           
#     T3_Wen           -0.096    0.021   -4.559    0.000
#     T3_SC             0.217    0.021   10.163    0.000
#     T3_LT             0.182    0.021    8.566    0.000
#     T3_Lon            0.439    0.023   19.253    0.000
#     T3_Eng           -0.046    0.021   -2.186    0.029
#     T3_Mat           -0.072    0.021   -3.446    0.001
#   T3_Wen ~~                                           
#     T3_SC            -0.055    0.021   -2.641    0.008
#     T3_LT            -0.337    0.022  -15.285    0.000
#     T3_Lon           -0.113    0.021   -5.400    0.000
#     T3_Eng            0.024    0.021    1.164    0.244
#     T3_Mat            0.031    0.021    1.503    0.133
#   T3_SC ~~                                            
#     T3_LT             0.108    0.021    5.164    0.000
#     T3_Lon            0.360    0.022   16.227    0.000
#     T3_Eng           -0.079    0.021   -3.787    0.000
#     T3_Mat           -0.156    0.021   -7.371    0.000
#   T3_LT ~~                                            
#     T3_Lon            0.195    0.021    9.164    0.000
#     T3_Eng           -0.058    0.021   -2.793    0.005
#     T3_Mat           -0.043    0.021   -2.067    0.039
#   T3_Lon ~~                                           
#     T3_Eng           -0.071    0.021   -3.396    0.001
#     T3_Mat           -0.105    0.021   -4.988    0.000
#   T3_Eng ~~                                           
#     T3_Mat            0.599    0.024   24.610    0.000
# 
# Intercepts:
#                    Estimate  Std.Err  z-value  P(>|z|)
#    .T1_SQD            0.000    0.018    0.000    1.000
#    .T2_SQD           -0.000    0.020   -0.000    1.000
#    .T3_SQD           -0.000    0.020   -0.000    1.000
#     T1_Wen           -0.000    0.021   -0.000    1.000
#     T1_SC             0.000    0.021    0.000    1.000
#     T1_LT             0.000    0.021    0.000    1.000
#     T1_Lon            0.000    0.021    0.000    1.000
#     FSM               0.000    0.021    0.000    1.000
#     T1_Eng            0.000    0.021    0.000    1.000
#     T1_Mat           -0.000    0.021   -0.000    1.000
#     T2_Wen           -0.000    0.021   -0.000    1.000
#     T2_SC            -0.000    0.021   -0.000    1.000
#     T2_LT             0.000    0.021    0.000    1.000
#     T2_Lon            0.000    0.021    0.000    1.000
#     T3_Wen           -0.000    0.021   -0.000    1.000
#     T3_SC            -0.000    0.021   -0.000    1.000
#     T3_LT             0.000    0.021    0.000    1.000
#     T3_Lon            0.000    0.021    0.000    1.000
#     T3_Eng           -0.000    0.021   -0.000    1.000
#     T3_Mat           -0.000    0.021   -0.000    1.000
# 
# Variances:
#                    Estimate  Std.Err  z-value  P(>|z|)
#    .T1_SQD            0.726    0.021   33.785    0.000
#    .T2_SQD            0.885    0.026   33.809    0.000
#    .T3_SQD            0.878    0.026   33.738    0.000
#     T1_Wen            1.000    0.030   33.867    0.000
#     T1_SC             1.000    0.030   33.867    0.000
#     T1_LT             1.000    0.030   33.867    0.000
#     T1_Lon            1.000    0.030   33.867    0.000
#     FSM               1.000    0.030   33.867    0.000
#     T1_Eng            1.000    0.030   33.867    0.000
#     T1_Mat            1.000    0.030   33.867    0.000
#     T2_Wen            1.000    0.030   33.867    0.000
#     T2_SC             1.000    0.030   33.867    0.000
#     T2_LT             1.000    0.030   33.867    0.000
#     T2_Lon            1.000    0.030   33.867    0.000
#     T3_Wen            1.000    0.030   33.867    0.000
#     T3_SC             1.000    0.030   33.867    0.000
#     T3_LT             1.000    0.030   33.867    0.000
#     T3_Lon            1.000    0.030   33.867    0.000
#     T3_Eng            1.000    0.030   33.867    0.000
#     T3_Mat            1.000    0.030   33.867    0.000
}


# The model fit was evaluated using several fit indices. The Comparative Fit Index (CFI) was 0.915, indicating a reasonably good fit. The Tucker-Lewis Index (TLI) was 0.856, also suggesting an acceptable fit. The Root Mean Square Error of Approximation (RMSEA) was 0.048 with a 90% confidence interval from 0.042 to 0.055, indicating that the model fits the data well. The model was compared against a baseline model, showing significant improvement as indicated by the chi-square test (p < 0.001).
# At each time point (C1, C2, C3), the regression coefficients for predicting Btotal (SQD scores) from various predictors (AGtotal, SCtotal, LTtotal, Ltotal, FSM, Eng, Mat) were estimated. Significant predictors varied across time points.
#Covariances between latent variables (Btotal, AGtotal, SCtotal, LTtotal, Ltotal, FSM, Eng, Mat) were also examined, indicating how these variables are related to each other within each time point.
# Intercept estimates for the latent variables (C1_Btotal, C2_Btotal, C3_Btotal, C1_AGtotal, etc.) were examined, although they did not significantly deviate from zero. Variances of the latent variables (C1_Btotal, C2_Btotal, C3_Btotal, C1_AGtotal, etc.) were estimated, providing insights into the variability of these constructs.
# In conclusion, the SEM analysis provided insights into how various factors such as academic scores (Eng, Mat), socio-emotional factors (AGtotal, SCtotal, LTtotal, Ltotal), and demographic characteristics (FSM) relate to each other and influence Btotal (SQD scores) across different time points. The model showed a good fit to the data, suggesting that the specified relationships adequately explain the observed data patterns.

```

```{r SEM model 2}

# creating the cross-lagged model
crosslagged_model <- '
  # Regressions at each time point
  T1_SQD ~ T1_Wen + T1_SC + T1_LT + T1_Lon + FSM + T1_Eng + T1_Mat
  T2_SQD ~ T2_Wen + T2_SC + T2_LT + T2_Lon + FSM
  T3_SQD ~ T3_Wen + T3_SC + T3_LT + T3_Lon + FSM + T3_Eng + T3_Mat

  # Auto-regressive paths
  T2_SQD ~ T1_SQD
  T3_SQD ~ T2_SQD
  
  # Cross-lagged paths (to see the influence of predictors over time)
  T2_Wen ~ T1_Wen
  T3_Wen ~ T2_Wen
  T2_SC ~ T1_SC
  T3_SC ~ T2_SC
  T2_LT ~ T1_LT
  T3_LT ~ T2_LT
  T2_Lon ~ T1_Lon
  T3_Lon ~ T2_Lon
'

# fitting the model made
cl_fit <- sem(crosslagged_model, data = norm_data, missing = "fiml", fixed.x = FALSE)

# having a lil look-see what the ugly stats that are supposed to mean something 
summary(cl_fit, fit.measures = TRUE)
{
#   lavaan 0.6-18 ended normally after 23 iterations
# 
#   Estimator                                         ML
#   Optimization method                           NLMINB
#   Number of model parameters                       105
# 
#   Number of observations                          2294
#   Number of missing patterns                         1
# 
# Model Test User Model:
#                                                       
#   Test statistic                              1877.098
#   Degrees of freedom                               125
#   P-value (Chi-square)                           0.000
# 
# Model Test Baseline Model:
# 
#   Test statistic                              7010.818
#   Degrees of freedom                               154
#   P-value                                        0.000
# 
# User Model versus Baseline Model:
# 
#   Comparative Fit Index (CFI)                    0.744
#   Tucker-Lewis Index (TLI)                       0.685
#                                                       
#   Robust Comparative Fit Index (CFI)             0.745
#   Robust Tucker-Lewis Index (TLI)                0.685
# 
# Loglikelihood and Information Criteria:
# 
#   Loglikelihood user model (H0)             -59986.571
#   Loglikelihood unrestricted model (H1)     -59048.021
#                                                       
#   Akaike (AIC)                              120183.141
#   Bayesian (BIC)                            120785.637
#   Sample-size adjusted Bayesian (SABIC)     120452.033
# 
# Root Mean Square Error of Approximation:
# 
#   RMSEA                                          0.078
#   90 Percent confidence interval - lower         0.075
#   90 Percent confidence interval - upper         0.081
#   P-value H_0: RMSEA <= 0.050                    0.000
#   P-value H_0: RMSEA >= 0.080                    0.170
#                                                       
#   Robust RMSEA                                   0.078
#   90 Percent confidence interval - lower         0.075
#   90 Percent confidence interval - upper         0.081
#   P-value H_0: Robust RMSEA <= 0.050             0.000
#   P-value H_0: Robust RMSEA >= 0.080             0.163
# 
# Standardized Root Mean Square Residual:
# 
#   SRMR                                           0.086
# 
# Parameter Estimates:
# 
#   Standard errors                             Standard
#   Information                                 Observed
#   Observed information based on                Hessian
# 
# Regressions:
#                    Estimate  Std.Err  z-value  P(>|z|)
#   T1_SQD ~                                            
#     T1_Wen            0.100    0.019    5.364    0.000
#     T1_SC             0.201    0.019   10.383    0.000
#     T1_LT            -0.136    0.019   -7.259    0.000
#     T1_Lon            0.364    0.020   18.482    0.000
#     FSM               0.031    0.018    1.672    0.094
#     T1_Eng           -0.061    0.023   -2.654    0.008
#     T1_Mat            0.007    0.023    0.289    0.773
#   T2_SQD ~                                            
#     T2_Wen            0.073    0.020    3.734    0.000
#     T2_SC             0.223    0.021   10.626    0.000
#     T2_LT            -0.078    0.020   -3.846    0.000
#     T2_Lon            0.053    0.021    2.497    0.013
#     FSM               0.006    0.019    0.303    0.762
#   T3_SQD ~                                            
#     T3_Wen            0.047    0.019    2.395    0.017
#     T3_SC             0.149    0.020    7.438    0.000
#     T3_LT             0.038    0.020    1.905    0.057
#     T3_Lon            0.176    0.020    8.839    0.000
#     FSM               0.058    0.019    3.098    0.002
#     T3_Eng            0.115    0.023    5.002    0.000
#     T3_Mat           -0.009    0.023   -0.399    0.690
#   T2_SQD ~                                            
#     T1_SQD            0.244    0.020   12.207    0.000
#   T3_SQD ~                                            
#     T2_SQD            0.343    0.019   18.136    0.000
#   T2_Wen ~                                            
#     T1_Wen            0.376    0.019   19.449    0.000
#   T3_Wen ~                                            
#     T2_Wen            0.467    0.018   25.330    0.000
#   T2_SC ~                                             
#     T1_SC             0.419    0.019   22.129    0.000
#   T3_SC ~                                             
#     T2_SC             0.509    0.018   28.312    0.000
#   T2_LT ~                                             
#     T1_LT             0.173    0.021    8.428    0.000
#   T3_LT ~                                             
#     T2_LT            -0.455    0.019  -24.454    0.000
#   T2_Lon ~                                            
#     T1_Lon            0.296    0.020   14.829    0.000
#   T3_Lon ~                                            
#     T2_Lon            0.439    0.019   23.403    0.000
# 
# Covariances:
#                    Estimate  Std.Err  z-value  P(>|z|)
#   T1_Wen ~~                                           
#     T1_SC            -0.209    0.021   -9.814    0.000
#     T1_LT             0.141    0.021    6.682    0.000
#     T1_Lon           -0.214    0.021  -10.018    0.000
#     FSM              -0.057    0.021   -2.740    0.006
#     T1_Eng            0.181    0.021    8.514    0.000
#     T1_Mat            0.144    0.021    6.848    0.000
#     T3_Eng            0.137    0.021    6.488    0.000
#     T3_Mat            0.125    0.021    5.920    0.000
#   T1_SC ~~                                            
#     T1_LT            -0.181    0.021   -8.534    0.000
#     T1_Lon            0.332    0.022   15.084    0.000
#     FSM               0.106    0.021    5.070    0.000
#     T1_Eng           -0.160    0.021   -7.591    0.000
#     T1_Mat           -0.209    0.021   -9.812    0.000
#     T3_Eng           -0.136    0.021   -6.452    0.000
#     T3_Mat           -0.163    0.021   -7.730    0.000
#   T1_LT ~~                                            
#     T1_Lon           -0.273    0.022  -12.617    0.000
#     FSM              -0.103    0.021   -4.902    0.000
#     T1_Eng            0.147    0.021    6.973    0.000
#     T1_Mat            0.180    0.021    8.507    0.000
#     T3_Eng            0.130    0.021    6.200    0.000
#     T3_Mat            0.147    0.021    6.959    0.000
#   T1_Lon ~~                                           
#     FSM               0.107    0.021    5.087    0.000
#     T1_Eng           -0.118    0.021   -5.609    0.000
#     T1_Mat           -0.208    0.021   -9.753    0.000
#     T3_Eng           -0.130    0.021   -6.182    0.000
#     T3_Mat           -0.177    0.021   -8.336    0.000
#   FSM ~~                                              
#     T1_Eng           -0.173    0.021   -8.161    0.000
#     T1_Mat           -0.203    0.021   -9.519    0.000
#     T3_Eng           -0.175    0.021   -8.239    0.000
#     T3_Mat           -0.191    0.021   -9.001    0.000
#   T1_Eng ~~                                           
#     T1_Mat            0.616    0.025   25.130    0.000
#     T3_Eng            0.630    0.025   25.538    0.000
#     T3_Mat            0.504    0.023   21.565    0.000
#   T1_Mat ~~                                           
#     T3_Eng            0.548    0.024   23.016    0.000
#     T3_Mat            0.651    0.025   26.131    0.000
#   T3_Eng ~~                                           
#     T3_Mat            0.599    0.024   24.610    0.000
# 
# Intercepts:
#                    Estimate  Std.Err  z-value  P(>|z|)
#    .T1_SQD            0.000    0.018    0.000    1.000
#    .T2_SQD           -0.000    0.019   -0.000    1.000
#    .T3_SQD           -0.000    0.018   -0.000    1.000
#    .T2_Wen           -0.000    0.019   -0.000    1.000
#    .T3_Wen            0.000    0.018    0.000    1.000
#    .T2_SC            -0.000    0.019   -0.000    1.000
#    .T3_SC             0.000    0.018    0.000    1.000
#    .T2_LT             0.000    0.021    0.000    1.000
#    .T3_LT             0.000    0.019    0.000    1.000
#    .T2_Lon            0.000    0.020    0.000    1.000
#    .T3_Lon            0.000    0.019    0.000    1.000
#     T1_Wen           -0.000    0.021   -0.000    1.000
#     T1_SC             0.000    0.021    0.000    1.000
#     T1_LT             0.000    0.021    0.000    1.000
#     T1_Lon            0.000    0.021    0.000    1.000
#     FSM               0.000    0.021    0.000    1.000
#     T1_Eng            0.000    0.021    0.000    1.000
#     T1_Mat           -0.000    0.021   -0.000    1.000
#     T3_Eng           -0.000    0.021   -0.000    1.000
#     T3_Mat           -0.000    0.021   -0.000    1.000
# 
# Variances:
#                    Estimate  Std.Err  z-value  P(>|z|)
#    .T1_SQD            0.724    0.021   33.867    0.000
#    .T2_SQD            0.829    0.024   33.867    0.000
#    .T3_SQD            0.764    0.023   33.867    0.000
#    .T2_Wen            0.858    0.025   33.867    0.000
#    .T3_Wen            0.781    0.023   33.867    0.000
#    .T2_SC             0.824    0.024   33.867    0.000
#    .T3_SC             0.741    0.022   33.867    0.000
#    .T2_LT             0.970    0.029   33.867    0.000
#    .T3_LT             0.793    0.023   33.867    0.000
#    .T2_Lon            0.912    0.027   33.867    0.000
#    .T3_Lon            0.807    0.024   33.867    0.000
#     T1_Wen            1.000    0.030   33.867    0.000
#     T1_SC             1.000    0.030   33.867    0.000
#     T1_LT             1.000    0.030   33.867    0.000
#     T1_Lon            1.000    0.030   33.867    0.000
#     FSM               1.000    0.030   33.867    0.000
#     T1_Eng            1.000    0.030   33.867    0.000
#     T1_Mat            1.000    0.030   33.867    0.000
#     T3_Eng            1.000    0.030   33.867    0.000
#     T3_Mat            1.000    0.030   33.867    0.000
}

# The SEM model tested relationships among variables over time, focusing on how initial conditions and changes in variables influence subsequent outcomes.
# The model significantly fits the data better than a baseline model, as indicated by a significant chi-square test (Chi-square = 1680.287, df = 85, p < 0.001). CFI (Comparative Fit Index) and TLI (Tucker-Lewis Index): Both around 0.76, suggesting acceptable fit. RMSEA (Root Mean Square Error of Approximation): Approximately 0.09, indicating mediocre fit but not entirely poor. SRMR (Standardized Root Mean Square Residual): Around 0.099, indicating fair fit.

# The model provided estimates for regression coefficients, covariances, intercepts, and variances. Key findings include:
# Significant coefficients of C1_AGtotal, C1_SCtotal, C1_LTtotal, C1_Ltotal, and FSM indicate these variables predict C1_Btotal scores.
# Autoregressive paths (C2_Btotal ~ C1_Btotal, C3_Btotal ~ C2_Btotal) indicate stability in scores over time.
# Cross-lagged paths (C2_AGtotal ~ C1_AGtotal, C3_AGtotal ~ C2_AGtotal, and similar for other variables) assess how earlier scores of one variable predict subsequent scores of another, indicating directional influences over time.
# Significant Paths: Variables like SCtotal, LTtotal, and Ltotal show significant relationships with Btotal scores across time points, suggesting these factors influence academic outcomes (Btotal).
# Free School Meal status (FSM) shows varying influence across time points on academic and psychosocial outcomes.
#Conclusion: The SEM analysis provides insights into how socio-demographic factors (FSM), psychological variables (AGtotal, SCtotal, LTtotal, Ltotal), and academic outcomes (Btotal) interplay over three time points. The model fits the data adequately, though some relationships could be further explored or refined based on future research or model modifications.

```

```{r fit indicies SEModels dataframe}
# extract fit indices for reg_model
fit_sum_reg <- summary(reg_fit, fit.measures = TRUE)
cfi_reg <- fit_sum_reg[["fit"]][["cfi"]]
tli_reg <- fit_sum_reg[["fit"]][["tli"]]
rmsea_reg <- fit_sum_reg[["fit"]][["rmsea"]]
srmr_reg <- fit_sum_reg[["fit"]][["srmr"]]

# extract fit indices for crosslagged_model
fit_sum_cl <- summary(cl_fit, fit.measures = TRUE)
cfi_cl <- fit_sum_cl[["fit"]][["cfi"]]
tli_cl <- fit_sum_cl[["fit"]][["tli"]]
rmsea_cl <- fit_sum_cl[["fit"]][["srmr"]]
srmr_cl <- fit_sum_cl[["fit"]][["srmr"]]

# combine into a dataframe
sem_stats <- data.frame(
  Model = c("reg_model", "crosslagged_model"),
  CFI = c(cfi_reg, cfi_cl),
  TLI = c(tli_reg, tli_cl),
  RMSEA = c(rmsea_reg, rmsea_cl),
  SRMR = c(srmr_reg, srmr_cl)
)

# sem stats checkpoint
write.csv(sem_stats, file = "../output/sem_stats.csv", row.names = FALSE)

```

```{r plotting the SEModels}
#install.packages("semPlot")
library(semPlot)
#reg_semplot.jpg and cl_semplot.jpg

# reg model
jpeg(filename = "../output/reg_semplot.jpg", res = 300, width = 2500, height = 2100)
reg_semplot <- semPlot::semPaths(reg_fit,
                             sizeMan = 5, 
                             residuals = TRUE, 
                             whatLabels = "est", 
                             width = 40, 
                             height = 5, 
                             normalize = FALSE,
                             nCharNodes = 6,
                             mar = c(3, 3, 3, 3),
                             layout = "tree")
dev.off()


# cross lagged model
jpeg(filename = "../output/cl_semplot.jpg", res = 300, width = 2500, height = 2100)
cl_semplot <- semPlot::semPaths(cl_fit,
                             sizeMan = 5, 
                             residuals = TRUE, 
                             whatLabels = "est", 
                             width = 40, 
                             height = 5, 
                             normalize = FALSE,
                             nCharNodes = 6,
                             mar = c(1, 1, 1, 1),
                             layout = "tree")
dev.off()


```


